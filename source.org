#+title: @aseltmann
#+author: Alva Seltmann
#+setupfile: setupfile.org
#+hugo_base_dir: ./aseltmann.github.io-hugo
#+options: creator:t
#+hugo_auto_set_lastmod: t

#+hugo_pandoc_citations: t
#+bibliography: cite/references.bib
# #+bibliography: cite/books.bib

* Homepage
:PROPERTIES:
:EXPORT_HUGO_SECTION:
:EXPORT_HUGO_TYPE: "docs"
:EXPORT_FILE_NAME: _index.en.md
:EXPORT_HUGO_MENU: :menu "main"
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :link-citations true
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :BookComments false
:END:

** Hi, I'm Alva

I am a researcher and physician, currently working with Marie von
Lilienfeld-Toal at the [[https://news.rub.de/leute/2023-07-07-medizin-willst-du-mich-behandeln-musst-du-wissen-wer-ich-bin][Institute for Diversity Medicine]] at Ruhr University
Bochum, formerly at the [[http://www.biophysical-imaging.com][Biophysical Imaging Lab]] of Christian Eggeling in Jena.

** Contact

You can get in contact with me by sending an email to =alva.seltmann (at) rub
(dot) de=. You can also find me on [[https://github.com/aseltmann][Github]].

* Homepage_de
:PROPERTIES:
:EXPORT_HUGO_SECTION:
:EXPORT_FILE_NAME: _index.de.md
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :BookComments false
:END:

** Hallo, ich bin Alva

Ich bin Wissenschaftlerin und Ärztin, aktuell tätig bei Marie von
Lilienfeld-Toal am [[https://news.rub.de/leute/2023-07-07-medizin-willst-du-mich-behandeln-musst-du-wissen-wer-ich-bin][Institut für Diversitätsmedizin]] der Ruhr-Universität Bochum,
davor in der [[http://www.biophysical-imaging.com][Biophysical Imaging Gruppe]] von Christian Eggeling in Jena.

** Kontakt
Ich bin per Email erreichbar unter =alva.seltmann (at) rub
(dot) de=. Weiterhin bin ich zu finden auf [[https://github.com/aseltmann][Github]].

# * Projects
# :PROPERTIES:
# :EXPORT_HUGO_SECTION: docs/projects
# :END:

# ** Projects
# :PROPERTIES:
# :EXPORT_FILE_NAME: _index.en.md
# :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookCollapseSection false
# :END:

# *** Current projects
#     I am a believer in the principles of Open Science, Open Data and Open
#     Source. Thus, I am currently working on a reproducible way of conducting my
#     research on simulation of Fluorescence Correlation Spectroscopy (FCS)
#     measurements and correcting artifacts using neural networks, such as
#     Convolutional Neural Nets (CNNs). I do not have my workflow fixed yet, but
#     to have an insight in my current approach - and with the principles of
#     [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook science]] in mind:

#     #+BEGIN_EXPORT html
#     <a href="https://aseltmann.github.io/fluotracify/">Fluotracify - doctoral research project done in a reproducible way</a>
#     #+END_EXPORT

#     Description: In a current project, we apply Deep Learning techniques on Fluorescence
#     Correlation Spectroscopy (FCS) data to correct a variety of hardware- and
#     sample-related artifacts, such as photobleaching, contamination from additional
#     slow moving particles, or sudden drops in intensity because of detector
#     anomalies.

# *** Conference talks
# - *Seltmann A*, Eggeling C, Waithe D. Automated, User-independent Correction of
#   Artifacts in Fluorescence Correlation Spectroscopy Measurements using
#   Convolutional Neural Networks. [[https://www.quantitativebioimaging.com/qbi2020/][Quantitative BioImaging Conference (QBI)]]; 2020
#   Jan 6-9; Oxford, UK

# * Projekte
# :PROPERTIES:
# :EXPORT_HUGO_SECTION: docs/projects
# :END:
# ** Projekte
# :PROPERTIES:
# :EXPORT_FILE_NAME: _index.de.md
# :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookCollapseSection false
# :END:

# *** Aktuelle Projekte
#     Ich glaube an die Prinzipien von Open Science, Open Data und Open Source.
#     Daher arbeite ich aktuell daran, meine Forschung an
#     Fluoreszenzkorrelationsspektroskopie (FCS) und Maschinellem Lernen in einer
#     offenen Art und Weise verfügbar zu machen. Im Sinne der [[https://en.wikipedia.org/wiki/Open-notebook_science][Open-notebook
#     science]] ist hier ein Einblick in meine aktuelle Forschung zu finden:

#     #+BEGIN_EXPORT html
#     <a href="https://aseltmann.github.io/fluotracify/">Fluotracify - eine reproduzierbare Doktorarbeit [Englisch]</a>
#     #+END_EXPORT

# *** Präsentationen auf Konferenzen
# - *Seltmann A*, Eggeling C, Waithe D. Automated, User-independent Correction of
#   Artifacts in Fluorescence Correlation Spectroscopy Measurements using
#   Convolutional Neural Networks. [[https://www.quantitativebioimaging.com/qbi2020/][Quantitative BioImaging Conference (QBI)]]; 2020
#   Jan 6-9; Oxford, UK

* Notes
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes
:END:

** Notes
:PROPERTIES:
:EXPORT_FILE_NAME: _index.en.md
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookCollapseSection false
:END:
** Poetry
   :PROPERTIES:
   :EXPORT_FILE_NAME: poetry.en.md
   :END:
*** Lǎozǐ
    I am partial to the [[https://terebess.hu/english/tao/DerekLin.html#Kap20][translation of Derek Lin]]
   #+begin_details
   #+begin_summary
   Dàodéjīng - Chapter 11 (The use of what has no substantive existence)
   #+end_summary
   #+BEGIN_VERSE
     [...]

     Mix clay
     to create a container
     In its emptiness, there is
     the function of a container

     [...]
     Therefore,
     that which exists is used to create benefit
     That which is empty is used to create functionality
   #+END_VERSE
   #+end_details
   #+begin_details
   #+begin_summary
   Dàodéjīng - Chapter 15 (The exhibition of the qualities of the Dao)
   #+end_summary
   #+BEGIN_VERSE
     The Tao masters of antiquity
     Subtle wonders through mystery
     Depths that cannot be discerned
     Because one cannot discern them
     Therefore one is forced to describe the appearance

     Hesitant,
     like crossing a wintry river
     Cautious,
     like fearing four neighbors
     Solemn,
     like a guest
     Loose,
     like ice about to melt
     Genuine,
     like plain wood
     Open,
     like a valley
     Opaque,
     like muddy water

     Who can be muddled yet desist
     In stillness gradually become clear?
     Who can be serene yet persist
     In motion gradually come alive?

     One who holds this <i>Tao</i> does not wish to be overfilled
     Because one is not overfilled
     Therefore one can preserve and not create anew
   #+END_VERSE
   #+end_details
   #+begin_details
   #+begin_summary
   Dàodéjīng - Chapter 20 (Being different from ordinary people)
   #+end_summary
   #+BEGIN_VERSE
     Cease learning, no more worries

     Respectful response and scornful response
     How much is the difference?
     Goodness and evil
     How much do they differ?
     What the people fear,
     I cannot be unafraid
     So desolate! How limitless it is!

     The people are excited
     As if enjoying a great feast
     As if climbing up to the terrace in spring
     I alone am quiet and uninvolved
     Like an infant
     not yet smiling
     So weary,
     like having no place to return
     The people all have surplus
     While I alone seem lacking
     I have the heart of a fool indeed -
     so ignorant!
     Ordinary people are bright
     I alone am muddled
     Ordinary people are scrutinizing
     I alone am obtuse
     So tranquil, like the ocean
     So moving, as if without limits

     The people all have goals
     And I alone am stubborn and lowly
     I alone am different from them
     And value the nourishing mother
   #+END_VERSE
   #+end_details

*** Aphorisms
#+BEGIN_VERSE
Too much of a good thing
can be wonderful
    ---Mae West, Goodness had Nothing to Do with It (1959)
#+END_VERSE
** TODO Test page
  :PROPERTIES:
  :EXPORT_HUGO_SECTION: docs/notes/test
  :EXPORT_FILE_NAME: test-page
  :END:
*** Year numbering system
#+BEGIN_EXPORT html
{{< hint info >}}
**I use the [Holocene Era or Human Era](https://en.wikipedia.org/wiki/Holocene_calendar) numbering system**. It adds exactly 10,000 years to the currently dominant AD/BC or CE/BCE numbering system. It is denoted **HE/BHE** and allows for all key dates in human history to be listed using a simle increasing date scale - while keeping the transition from the CE calendar easy: you just add the digit "1" before the current year. _Welcome to the year 12,020 HE!_
{{< /hint >}}
#+END_EXPORT

Examples:

| Human Era year | Common Era year | Event                  |
|----------------+-----------------+------------------------|
|            <r> |             <r> |                        |
|        1001 HE |        9000 BCE | [[https://en.wikipedia.org/wiki/Jericho][Jericho]]                |
|        7301 HE |        2700 BCE | [[https://en.wikipedia.org/wiki/Pyramid_of_Djoser][First pyramid]]          |
|       11460 HE |         1460 CE | [[https://en.wikipedia.org/wiki/Machu_Picchu][Machu Picchu built]]     |
|       11945 HE |         1945 CE | [[https://en.wikipedia.org/wiki/United_Nations][United Nations founded]] |

Wonderful illustration of the case for the Human Era (courtesy of
[kurzgesagt.org](https://kurzgesagt.org)):

#+BEGIN_EXPORT html
{{< youtube czgOWmtGVGs >}}
#+END_EXPORT

Structured arguments and thoughts, often presented in lists.

*Bold*, /italic/, =verbatim=, +strikethrough+

This is a test. And Hugo Book Shortcodes in an org source file:

*** Buttons
#+BEGIN_EXPORT html
{{< button relref="/" >}}Get Home{{< /button >}}
{{< button href="https://github.com/alex-shpak/hugo-book" >}}Contribute{{< /button >}}
#+END_EXPORT

*** Columns
#+BEGIN_EXPORT html
{{< columns >}}
#### Left Content
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
protulit, sed sed aere valvis inhaesuro Pallas animam: qui _quid_, ignes.
Miseratus fonte Ditis conubia.

<--->

#### Mid Content
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter!

<--->

#### Right Content
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
protulit, sed sed aere valvis inhaesuro Pallas animam: qui _quid_, ignes.
Miseratus fonte Ditis conubia.
{{< /columns >}}

#+END_EXPORT

*** Expand
#+BEGIN_EXPORT html
{{< details "Custom Label" "..." >}}
## Markdown content
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
protulit, sed sed aere valvis inhaesuro Pallas animam: qui _quid_, ignes.
Miseratus fonte Ditis conubia.
{{< /details >}}

#+END_EXPORT

#+begin_details
Here are the /details/.
#+end_details

#+attr_html: :open t
#+begin_details
#+begin_summary
Some *Summary*
#+end_summary
Here are the /details/.
#+end_details

*** Hints
#+BEGIN_EXPORT html
{{< hint info >}}
**Hint info**
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
{{< /hint >}}

#+END_EXPORT

#+BEGIN_EXPORT html
{{< hint warning >}}
**Hint warning**
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
{{< /hint >}}

#+END_EXPORT

#+BEGIN_EXPORT html
{{< hint danger >}}
**Hint danger**
Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
{{< /hint >}}
#+END_EXPORT

*** Display Mode (KaTeX)

#+BEGIN_EXPORT html

Here is some inline example: {{< katex >}}\pi(x){{< /katex >}}, rendered in the same line. And below is `display` example, having `display: block`
{{< katex display >}}
x = \begin{cases}
   a &\text{if } b \\
   c &\text{if } d
\end{cases}
{{< /katex >}}
Text continues here.

#+END_EXPORT

This should also be possible in plain org-mode: \pi(x) vs $\pi(x)$ vs \(\pi(x)\)

This works, but requires MathJax:

\begin{equation}
\label{eq:1}
C = W\log_{2} (1+\mathrm{SNR})
\end{equation}


x = \begin{cases}
   a &\text{if } b \\
   c &\text{if } d
\end{cases}

*** Generate SVG charts and diagrams for text (Mermaid)

#+BEGIN_EXPORT html
{{< mermaid >}}
sequenceDiagram
    Alice->>Bob: Hello Bob, how are you?
    alt is sick
        Bob->>Alice: Not so good :(
    else is well
        Bob->>Alice: Feeling fresh like a daisy
    end
    opt Extra response
        Bob->>Alice: Thanks for asking
    end
{{< /mermaid >}}
#+END_EXPORT

*** Tabs
#+BEGIN_EXPORT html
{{< tabs "uniqueid" >}}
{{< tab "MacOS" >}}
# MacOS

This is tab **MacOS** content.

Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
protulit, sed sed aere valvis inhaesuro Pallas animam: qui _quid_, ignes.
Miseratus fonte Ditis conubia.
{{< /tab >}}

{{< tab "Linux" >}}

# Linux

This is tab **Linux** content.

Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
protulit, sed sed aere valvis inhaesuro Pallas animam: qui _quid_, ignes.
Miseratus fonte Ditis conubia.
{{< /tab >}}

{{< tab "Windows" >}}

# Windows

This is tab **Windows** content.

Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat
stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa
protulit, sed sed aere valvis inhaesuro Pallas animam: qui _quid_, ignes.
Miseratus fonte Ditis conubia.
{{< /tab >}}
{{< /tabs >}}

#+END_EXPORT

** TODO Science & Medicine
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_SECTION: docs/notes/kritmed
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookFlatSection true
:END:

** TODO Critical test section
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes/kritmed
:EXPORT_FILE_NAME: falsche-daten
:END:

*** TODO test section
Test section text.

# {{< fa github >}}

#+BEGIN_EXPORT html
{{< tabs "uniqueid" >}}
{{< tab "test" >}}

foo[^1]
[^1]: bar

{{< /tab >}}
{{< /tabs >}}
#+END_EXPORT

** TODO Other critical stuff
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes/kritmed
:EXPORT_FILE_NAME: other-critical
:END:

Here is other critical stuff.

** TODO International
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_SECTION: docs/notes/international
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookFlatSection true
:END:

** TODO Africa
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes/international
:EXPORT_FILE_NAME: africa
:CUSTOM_ID: africa
:END:

*** Notes on specific countries

#+BEGIN_EXPORT html
{{< tabs "uniqueid" >}}
{{< tab "Ghana" >}}

# Ghana
- [Kwame Nkrumah](https://en.wikipedia.org/wiki/Kwame_Nkrumah)[^1]
  + Pan-African while studying in America
  + returned home 11947 HE
  + founded party → slogan "Independence now!"
  + 11957 HE Independence and Accra center of independence movements
- Ashanti[^1]
  + tribe
    * e.g. Ashanti, consists of 8 clans
    * king: _Ashantehene_
    * territorial, cultural, political community
  + clan → all those who believe they have a common ancestor
    * secual relations between clan-members forbidden!
  + clan chief
    * voted for by council (elders, functionaries, ...)
    * because holy person in moment of election → no walking barefoot, others may not touch him, ...
    * main task: communication between ancestors and living
    * has to step down, if: drunk, gluttoning, collusion with sorceror, bad speech about people, not asking elders about opinions


[^1]: Kapuscinski, Ryszard. The Shadow of the Sun. Penguin, 2002.


{{< /tab >}}

{{< tab "Tansania" >}}

# Zanzibar
## Mid 120th-century
- "sad, dark star". Arabs from Persian Gulf conquered island with best stretches of land + hotspot of [Arab slave trade](https://en.wikipedia.org/wiki/Arab_slave_trade)[^1]
- population[^1]
  + 20% ruling Arabs
    * ruler: Sultan
    * want independence from Britain
  + 80% laboring Africans
    * [Afro-Shirazi Party (ASP)]([https://en.wikipedia.org/wiki/Afro-Shirazi_Party) headed by [Karume](https://en.wikipedia.org/wiki/Abeid_Karume) + [John Okello](https://en.wikipedia.org/wiki/John_Okello) (revolutionary)
    * want independence from Britain AND Arabs

[^1]: Kapuscinski, Ryszard. The Shadow of the Sun. Penguin, 2002.


{{< /tab >}}

{{< tab "Ethiopia" >}}

# Ethiopia
- emperor [Haile Selassi](https://en.wikipedia.org/wiki/Haile_Selassie) in power till 11974 HE.
- dictator [Mengistu Haile Mariam](https://en.wikipedia.org/wiki/Mengistu_Haile_Mariam) in power 11974 - 11991 HE.
- 11983-85 HE: [great famine](https://en.wikipedia.org/wiki/1983%E2%80%931985_famine_in_Ethiopia) with around 1 Mio. hunger deaths - why?
  + great famine was not result of shortage, but of inhumane relations
  + there was food in the country, but when drought came, prices went up and poor peasents were unable to purchase any
  + government did not intervene / let world intervene, because: prestige, didn't want to admit that there was hunger in the land
{{< /tab >}}
{{< /tabs >}}

#+END_EXPORT

*** Phases after WWII
**** 1st phase: 50s/60s - rapid decolonization, optimism, euphoria
- promise and hope, with freedom comes prosperity
- movement of French colonies \to want to become French citizens
- movement of British colonies \to *Pan-Africanism*
  + people: activist [[https://en.wikipedia.org/wiki/Alexander_Crummell][Alexander Crummell]], writer [[https://en.wikipedia.org/wiki/W._E._B._Du_Bois][W. E. B. Du Bois]] (core idea:
    Black* people should remain in the countries where they now live), journalist
    [[https://en.wikipedia.org/wiki/Marcus_Garvey][Marcus Garvey]] (core idea: Black* people should return to Africa)
  + core ideas
    1. all Blacks* in the world constitute a single race, a single culture, and
       should be proud of their colour of skin
    2. all of Africa should be independent and united \to "Africa for Africans"
- BUT: corrupt elites - why?
  + no well-developed private sector, plantations belonged to foreigners, banks
    belong to foreign capital \to political career was only way to richness
**** 2nd phase: 70s/80s - rapid growth of population, pessimism
- civil wars, revolts, massacres, hunger
  + opponents used all means (tribal and ethnic conflicts, military might,
    corruption, murder)
  + cold war era → problems + interests of weaker, dependent countries were
    ignored, subordinate to superpower interests
- coup d'etat in /Nigeria/ - military seizes power after only 5 years of
  independence
  + and people celebrate! Since own elite is seen as too corrupt ("black
    imperialists", "political wolves, who plunder the country")

** TODO Asia
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes/international
:EXPORT_FILE_NAME: asia
:END:

Another continent to describe.

** TODO Section Philosophy
:PROPERTIES:
:EXPORT_FILE_NAME: _index.en.md
:EXPORT_HUGO_SECTION: docs/notes/philosophy
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookFlatSection true
:END:

** TODO Philosophy
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes/philosophy
:EXPORT_FILE_NAME: philo.en.md
:END:
*** A overview from
#+BEGIN_EXPORT html
{{< mermaid >}}
graph TD
	A["Christmas und viel mehr text hahaha textext<br/>
  und noch mehr text"] -->|Get money| B(Go shopping)
	B --> C{Let me think}
	C -->|One| D[Laptop]
	C -->|Two| E[iPhone]
	C -->|Three| F[fa:fa-car Car]

{{< /mermaid >}}
#+END_EXPORT

* Notizen
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/notes
:END:
** Notizen
   :PROPERTIES:
   :EXPORT_FILE_NAME: _index.de.md
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookCollapseSection false
   :END:
** Gedichte
   :PROPERTIES:
   :EXPORT_FILE_NAME: poetry.de.md
   :END:
*** Erich Fried
   #+begin_details
   #+begin_summary
   Kleines Beispiel (1982)
   #+end_summary
   #+BEGIN_VERSE
     Auch ungelebtes Leben
     geht zu Ende
     zwar vielleicht langsamer
     wie eine Batterie
     in einer Taschenlampe
     die keiner benutzt

     Aber das hilft nicht viel:
     Wenn man
     (sagen wir einmal)
     diese Taschenlampe
     nach so- und sovielen Jahren
     anknipsen will
     kommt kein Atemzug Licht mehr heraus
     und wenn du sie aufmachst
     findest du nur deine Knochen
     und falls du Pech hast
     auch diese
     schon ganz zerfressen

     Da hättest du
     genau so gut
     leuchten können
   #+END_VERSE
   #+end_details

   #+begin_details
   #+begin_summary
   Herrschaftsfreiheit (1984)
   #+end_summary
   #+BEGIN_VERSE
     Zu sagen
     "Hier
     herrscht Freiheit"
     ist immer
     ein Irrtum
     oder auch
     eine Lüge:

     Freiheit
     herrscht nicht
   #+END_VERSE
   #+end_details

   #+begin_details
   #+begin_summary
   Humorlos (1967)
   #+end_summary
   #+BEGIN_VERSE
     Die Jungen
     werfen
     zum Spaß
     mit Steinen
     nach Fröschen

     Die Frösche
     sterben
     im Ernst
   #+END_VERSE
   #+end_details

   #+begin_details
   #+begin_summary
   Rückwärtsgewandte Utopie (1981)
   #+end_summary
   #+BEGIN_VERSE
     Angeklagt
     der Unmenschlichkeit
     behauptet
     der Nichtmehrmensch
     immer noch
     erst
     ein Nochnichtmensch
     zu sein
   #+END_VERSE
   #+end_details

   #+begin_details
   #+begin_summary
   Zu guter Letzt (1983)
   #+end_summary
   #+BEGIN_VERSE
     Als Kind wusste ich:
     Jeder Schmetterling
     den ich rette
     jede Schnecke
     und jede Spinne
     und jede Mücke
     jeder Ohrwurm
     und jeder Regenwurm
     wird kommen und weinen
     wenn ich begraben werde

     Einmal von mir gerettet
     muss keines mehr sterben
     Alle werden sie kommen
     zu meinem Begräbnis

     Als ich dann groß wurde
     erkannte ich:
     Das ist großer Unsinn
     Keines wird kommen
     ich überlebe sie alle

     Jetzt im Alter
     frage ich: Wenn ich sie aber
     rette bis ganz zuletzt
     kommen doch vielleicht zwei oder drei?
   #+END_VERSE
   #+end_details

*** Lǎozǐ
    Ich persönlich mag die Übersetzung von Günther Debon.
   #+begin_details
   #+begin_summary
   Dàodéjīng - Kapitel 11
   #+end_summary
   #+BEGIN_VERSE
     [...]

     Man knetet Ton zurecht
     Zum Trinkgerät:
     Eben dort, wo keiner ist,
     Ist des Gerätes Brauchbarkeit.

     [...]

     Wahrlich:
     Erkennst du das Da-Sein als einen Gewinn,
     Erkenne: Das Nicht-Sein macht brauchbar.
   #+END_VERSE
   #+end_details
   #+begin_details
   #+begin_summary
   Dàodéjīng - Kapitel 15
   #+end_summary
   #+BEGIN_VERSE
     Wer im Altertum gut war als Meister,
     War subtil, geheimnisvoll, mystisch, durchdringend;
     So tief, dass er uns unbegreiflich bleibt.
     Wohl! Und weil er unbegreiflich bleibt,
     Will ich lieber dartun sein Gebaren:

     So zögernd, ach!
     Wie wenn man winters quert einen Strom;
     So ängstlich, ach!
     Wie wenn man fürchtet die Nachbarn rings;
     Verhalten, ach!
     Als wäre zu Gast man geladen;
     Nachgiebig, ach!
     Wie vor der Schmelze das Eis;
     Gediegen, ach!
     Gleich einem Grobholz;
     Weit, ach!
     Gleich einem Flusstal;
     Chaotisch, ach!
     Gleich einem Strudel.

     Wer kann den Strudel stillen,
     Auf dass er mählich werde rein?
     Wer kann das Ruhende bewegen,
     Auf dass es mählich Leben gewinne?

     Wer diesen <i>Weg</i> bewahrt,
     Wünscht nicht, erfüllt zu sein.
     Wohl! Nur was unerfüllt,
     Kann auch verschleißen ohne Erneuen.
   #+END_VERSE
   #+end_details
   #+begin_details
   #+begin_summary
   Dàodéjīng - Kapitel 20
   #+end_summary
   #+BEGIN_VERSE
     Brich ab das Lernen, so bist du sorgenfrei!

     Sind denn "Jawohl!" und "Recht gern!"
     Wirklich einander so fern?
     Sind denn das Gute, die Schlechtigkeit
     Wirklich einander so weit?
     "Wem andere Menschen sich beugen,
     Dem musst auch du dich beugen":
     Welch Öde doch! Und kein Ende noch!

     Die Menschen alle sind ausgelassen,
     Als säßen sie zechend beim Opferfest,
     Als stiegen sie auf zu den Frühlingsterrassen.
     Ich allein liege noch still,
     Kein Zeichen hab ich gegeben,
     Gleich einem kleinen Kinde,
     Das noch nie gelacht hat im Leben;
     Bin schwankend, bin wankend,
     Als hätt ich die Heimat verloren.
     Die Menge der Menschen hat Überfluss;
     Nur Ich bin gleichsam von allem entblößt.
     Wahrlich, Ich habe das Herz eines Toren,
     So dunkel und wirr!
     Die gewöhnlichen Menschen sind hell und klar;
     Nur Ich bin trübe verhangen.
     Die gewöhnlichen Menschen sind strebig-straff;
     Nur Ich bin bang-befangen.
     Ruhelos gleich ich dem Meere;
     Verweht, ach, bin gleichsam ich ohne Halt.

     Die Menschen machen sich nützlich all,
     Nur Ich bin halsstarr, als ob ich ein Wildling wäre.
     Nur Ich bin von den andern Menschen verschieden -
     Der ich die nährende Mutter verehre.
   #+END_VERSE
   #+end_details

*** Aphorismen
#+BEGIN_VERSE
Zu viel des Guten
kann wunderbar sein.
    ---Mae West, Goodness had Nothing to Do with It (1959)
#+END_VERSE


#+BEGIN_VERSE
Arbeitswut ist eine schwer erklärbare
psychische Störung
die mit einer Tasse Kaffee
und einer gemütlichen Plauderei
überwunden werden kann.
    ---Anonym
#+END_VERSE
** TODO Sektion Philosopie
   :PROPERTIES:
   :EXPORT_FILE_NAME: _index.de.md
   :EXPORT_HUGO_SECTION: docs/notes/philosophy
   :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :bookFlatSection true
   :END:

** TODO Philosopie
   :PROPERTIES:
   :EXPORT_HUGO_SECTION: docs/notes/philosophy
   :EXPORT_FILE_NAME: philo.de.md
   :END:
*** Ein Überblick aus "Sophies Welt"
#+BEGIN_EXPORT html
{{< mermaid >}}
graph TB
10(("""mythisches Weltbild<br>
   = Göttererzählungen"""))
11["""
- Präkere <sup>Machtbalance</sup> zw. guten<br>
  und bösen Kräften<br>
- Natur = <i>Frøya</i>, wenn geraubt<br>
  von Trollen keine <sub>Fruchtbarkeit</sub><br>
- Opfer um <code>Macht</code> der <del>Götter</del> zu<br>
  vergrößern → f. Odin sogar Menschen<br>
- Gedicht <i>Trymsveda</i>: Thor's<br>
  <q>Hammer gestohlen</q> → verkleidet sich als Frau<br>
  um ihn wiederzubekommen<br>
"""]
12["""
- <big>Niederschrift</big> der <small>Göttermythen</small> dr<br>
  <b>Homer</b> und <b>Hesiod</b> 9300 HE<br>
- 1. Mythenkritik: <strong>Xenophanes</strong> 9430 HE<br>
  ...Götter nach eigenem Vorbild...<br>
  → Ziel erster Philosophen: natürliche<br>
  Erklärungen für Naturprozesse<br>
"""]
20(("""Naturphilosophen (Vorsokratiker)<br>
- sahen <u>Veränderungen</u><br>
- glaubten an Urstoff dahinter<br>
- erhalten durch Aristoteles<br>
"""))
21["""<big>3 aus Milet (griech. Kolonie in Kleinasien)</big>"""]
21a["""
- Urstoff = <u>Wasser</u><br>
- Erde voller <q>Lebenskeime</q>,<br>
  alles voller Götter<br>
- 9415 HE Sonnenfinsternis berechnet<br>
"""]
21b["""
- Welt nur eine von vielen<br>
- entsteht und vergeht in<br>
  <u>das Unendliche</u>
"""]
21c["""
- 9430 - 9475 HE<br>
- Urstoff = <u>Luft</u><br>
- Wasser ist dichte Luft,<br>
  Feuer ist dünne Luft
"""]
22["""<strong>Parmenides</strong> (9460 - 9520 HE)<br>
- alles, was es gibt, hat schon immer existiert<br>
- aus nichts kann nichts werden <br>
- glaubte nicht an Veränderung<br>
  → <u>Sinnestäuschung</u><br>
- starker Glaube an menschliche <u>Vernunft</u><br>
  = <u>Rationalismus</u>
"""]
23["""<strong>Heraklit</strong> (9460 - 9520 HE)<br>
- alles fließt → <u>Sinneserfahrung</u><br>
- Gut und Böse hat Platz in Ganzheit<br>
- alle Veränderung und Gegensätze der Natur<br>
  sind <u>Einheit oder Ganzheit</u><br>
  = Gott oder <u>Logos</u>
"""]
24["""<strong>Anaxagoras</strong> (9500 - 9573 HE)<br>
- nicht 1 Urstoff, sondern<br>
  kleinste Teilchen, die<br>
  <q>etwas von allem</q> in sich<br>
  tragen = <q>Samen / Keime</q><br>
- 1 Kraft, die Ordnung schafft<br>
  = <u>Geist</u><br>
- Astronom:<br>
  - Sonne kein Gott, sondern<br>
    glühende Masse<br>
  - alle Himmelskörper aus Stoff<br>
    wie unsere Erde → <u>Leben auf</u><br>
    <u> anderen Planete</u> mögl<br>
  - erklärte Entstehung von<br>
    Sonnenfinsternissen
"""]
25["""<strong>Empedokles</strong> (9507 - 9567 HE)<br>
- Fehler liegt in Annahme<br>
  <u>1</u> Grundstoffes<br>
- 4 <u>Wurzeln</u> der Natur<br>
  = Erde, Luft, Feuer, Wasser<br>
- 2 <u>Naturkräfte</u>:<br>
  Liebe und Streit;<br>
  auflösen und verbinden<br>
→ Unterscheidet zw <u>Stoff</u><br>
  und <u>Kraft</u> → moderne<br>
  Wissenschaft glaubt auch, alles<br>
  dr Grundstoffe + Naturkräfte<br>
  erklären zu können
"""]
26["""<strong>Demokrit</strong> (9541 - 9631 HE)<br>
- sichtbare Veränderung heißt<br>
  nicht, dass sich wirklich<br>
  etwas veränderte → kleine,<br>
  unteilbare, unsichtbare,<br>
  feste/massive, unterschiedlich<br>
  geformte, ewige, mit <q>Haken u<br>
  Ösen</q> ausgestattete Bau-<br>
  steine = <u>Atome</u> → noch heute<br>
  wird an kleinste Teile geglaubt<br>
- glaubte nur an Atome = das<br>
  Materielle + leerer Raum<br>
  = <u>Materialist</u><br>
- Empfindungen auch durch Atome<br>
  (<q>Mondatome treffen mein Auge</q>)<br>
- Bewusstsein? → Seelenatome<br>
  → stirbt Mensch, wirbeln<br>
  Seelenatome davon → keine<br>
  unsterbliche Seele
"""]
27["""
→ Wie konnte ein Stoff plötzlich zu etwas anderen<br>
  werden? → <u>Problem der Veränderung</u>
"""]

30(("""Schicksalsgläubigkeit"""))

40(("""<u>Sophisten</u><br>
in Athen ab 9550 HE"""))

50(("""Athener Philosophie / Die Sokratiker<br>
ca 9550 - 9650 HE"""))

60(("""<u>Hellenismus</u><br>
ca 9650 - 9950 HE"""))

10==>20
subgraph Göttererzählungen
10-->|Wikinger|11
10-->|Griechen|12
end
11-.-20
12-.-20
20==>30
subgraph Vorsokratiker
20-->21
21-->|<strong>Thales</strong>|21a
21-->|<strong>Anaximander</strong>|21b
21-->|<strong>Anaximenes</strong>|21c
21a-->27
21b-->27
21c-->27
subgraph Problem-der-Veränderung
27-->|Eleaten-in-Süditalien|22
27-->|Ephesos-in-Kleinasien|23
end
subgraph Lösungen
22-->|Lösung|24
22-->|Lösung|25
23-->|Lösung|25
22-->|beste Lösung: in Abdera an nördlicher Ägäis|26
end
end
24-.-30
25-.-30
26-.-30
30==>40
40==>50
50==>60

{{< /mermaid >}}
#+END_EXPORT

* Blog Posts
# the blog posts are displayed by a simple html list and inserted before the
# menu main thanks to /themes/book/layouts/partials/docs/inject/menu-before.html
:PROPERTIES:
:EXPORT_HUGO_SECTION: posts
:END:
** TODO Test post
   CLOSED: [2020-03-23 Mo 14:31]
:PROPERTIES:
:EXPORT_FILE_NAME: test-post.en.md
:END:

Test post text.

** TODO Test post deutsch
   CLOSED: [2020-03-23 Mo 14:31]
:PROPERTIES:
:EXPORT_FILE_NAME: test-post.de.md
:END:

Test post text.
** DONE Advent of code 2023 - Day 1: Trebuchet?! :python:
CLOSED: [2023-12-10 So 03:05]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day01.en.md
:ID:       050c869e-41c1-4428-85ef-dcd83cf0b8d7
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 1 - see [[https:adventofcode.com/2023/day/1]]

*** Part 1

#+begin_details
#+begin_summary
Our first task is the following:
#+end_summary

#+begin_quote
The newly-improved calibration document consists of lines of text; each line
originally contained a specific calibration value that the Elves now need to
recover. On each line, the calibration value can be found by combining the first
digit and the last digit (in that order) to form a single two-digit number.

For example:
#+end_quote

#+begin_example
1abc2
pqr3stu8vwx
a1b2c3d4e5f
treb7uchet
#+end_example

#+begin_quote
In this example, the calibration values of these four lines are 12, 38, 15,
and 77. Adding these together produces 142.

Consider your entire calibration document. What is the sum of all of the
calibration values?
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-01-1-aoc.txt][2023-12-01-1-aoc.txt]]

Lets start jupyter in our shell to start coding!

#+begin_src sh :session local :noeval
conda activate tf
jupyter lab --no-browser --port=8888
#+end_src

First, load the test document

#+BEGIN_SRC jupyter-python
import pandas as pd
import re

txt = pd.read_table('data/2023-12-01-1-aoc.txt', names=['code'])
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                          |
|-----+-------------------------------|
| 0   | jjfvnnlfivejj1                |
| 1   | 6fourfour                     |
| 2   | ninevbmltwo69                 |
| 3   | pcg91vqrfpxxzzzoneightzt      |
| 4   | jpprthxgjfive3one1qckhrptpqdc |
| ... | ...                           |
| 995 | 583sevenhjxlqzjgbzxhkcl5      |
| 996 | 81s                           |
| 997 | 2four3threesxxvlfqfive4       |
| 998 | nine6eightsevenzx9twoxc       |
| 999 | hmbfjdfnp989mfivefiverpzrjs   |

1000 rows × 1 columns
:END:

Second, extract the digits. I had to wrap my head around regex matching in
python first, because I first tried =pandas.extract= (which only extracts the
first match), then =pandas.extractall= (which extracts all matches but puts them
into a multiindex which makes things more difficult in this case). So I settled
for the =re.findall= version, which returns a list. To concatenate the elements
in the list, we take use the =join= function.

#+BEGIN_SRC jupyter-python
txt['digits'] = txt.loc[:, 'code'].apply(
    lambda x: ''.join(re.findall(r'(\d+)', x)))
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                          | digits |
|-----+-------------------------------+--------|
| 0   | jjfvnnlfivejj1                | 1      |
| 1   | 6fourfour                     | 6      |
| 2   | ninevbmltwo69                 | 69     |
| 3   | pcg91vqrfpxxzzzoneightzt      | 91     |
| 4   | jpprthxgjfive3one1qckhrptpqdc | 31     |
| ... | ...                           | ...    |
| 995 | 583sevenhjxlqzjgbzxhkcl5      | 5835   |
| 996 | 81s                           | 81     |
| 997 | 2four3threesxxvlfqfive4       | 234    |
| 998 | nine6eightsevenzx9twoxc       | 69     |
| 999 | hmbfjdfnp989mfivefiverpzrjs   | 989    |

1000 rows × 2 columns
:END:

Next, combine the first and the last digit and convert the result from string to integer

#+BEGIN_SRC jupyter-python
txt['calibration'] = txt.loc[:, 'digits'].apply(
    lambda x: int(x[0] + x[-1]))
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                          | digits | calibration |
|-----+-------------------------------+--------+-------------|
| 0   | jjfvnnlfivejj1                | 1      | 11          |
| 1   | 6fourfour                     | 6      | 66          |
| 2   | ninevbmltwo69                 | 69     | 69          |
| 3   | pcg91vqrfpxxzzzoneightzt      | 91     | 91          |
| 4   | jpprthxgjfive3one1qckhrptpqdc | 31     | 31          |
| ... | ...                           | ...    | ...         |
| 995 | 583sevenhjxlqzjgbzxhkcl5      | 5835   | 55          |
| 996 | 81s                           | 81     | 81          |
| 997 | 2four3threesxxvlfqfive4       | 234    | 24          |
| 998 | nine6eightsevenzx9twoxc       | 69     | 69          |
| 999 | hmbfjdfnp989mfivefiverpzrjs   | 989    | 99          |

1000 rows × 3 columns
:END:

Lastly, get the sum of our calibration numbers

#+BEGIN_SRC jupyter-python
txt.loc[:, 'calibration'].sum()
#+END_SRC

#+RESULTS:
: 56465

*** Part 2

#+begin_details
#+begin_summary
Now follows part two:
#+end_summary

#+begin_quote
Your calculation isn't quite right. It looks like some of the digits are
actually spelled out with letters: one, two, three, four, five, six, seven,
eight, and nine also count as valid "digits".

Equipped with this new information, you now need to find the real first and last
digit on each line. For example:
#+end_quote

#+begin_example
two1nine
eightwothree
abcone2threexyz
xtwone3four
4nineeightseven2
zoneight234
7pqrstsixteen
#+end_example

#+begin_quote
In this example, the calibration values are 29, 83, 13, 24, 42, 14, and 76.
Adding these together produces 281.

What is the sum of all of the calibration values?
#+end_quote
#+end_details

Okay, let's see if we can update the pattern matching. To deal with potential
overlapping values like =oneight= which contains =one= as well as =eight=, I
used the regex positive lookahead ~?=~ as described [[https://stackoverflow.com/a/5616910][here]]. Because this enables
capturing overlapping values, I used =\d= (one digit) instead of =\d+= (one or
more digits), otherwise digits might double. Afterwards, just replace the
spelled out digits with their numerical value.

#+begin_src jupyter-python
# for i, r in enumerate(txt.loc[:, 'code']):
#     matches = re.findall(
#         r'(?=(\d|one|two|three|four|five|six|seven|eight|nine))', r)
#     result = ''.join([match for match in matches])
#     result = result.replace('one', '1').replace('two', '2').replace(
#         'three', '3').replace('four', '4').replace('five', '5').replace(
#         'six', '6').replace('seven', '7').replace('eight', '8').replace(
#         'nine', '9')
#     txt.loc[i, 'digits2'] = result
# txt

# a very nice alternative suggested by Tomalak:
digits = '\d one two three four five six seven eight nine'.split()


txt['digits2'] = txt.loc[:, 'code'].apply(lambda v: ''.join(
    str(digits.index(m)) if m in digits else m
    for m in re.findall(rf'(?=({"|".join(digits)}))', v)
))
txt
#+end_src

#+RESULTS:
:RESULTS:
|     | code                          | digits | calibration | digits2 |
|-----+-------------------------------+--------+-------------+---------|
| 0   | jjfvnnlfivejj1                | 1      | 11          | 51      |
| 1   | 6fourfour                     | 6      | 66          | 644     |
| 2   | ninevbmltwo69                 | 69     | 69          | 9269    |
| 3   | pcg91vqrfpxxzzzoneightzt      | 91     | 91          | 9118    |
| 4   | jpprthxgjfive3one1qckhrptpqdc | 31     | 31          | 5311    |
| ... | ...                           | ...    | ...         | ...     |
| 995 | 583sevenhjxlqzjgbzxhkcl5      | 5835   | 55          | 58375   |
| 996 | 81s                           | 81     | 81          | 81      |
| 997 | 2four3threesxxvlfqfive4       | 234    | 24          | 243354  |
| 998 | nine6eightsevenzx9twoxc       | 69     | 69          | 968792  |
| 999 | hmbfjdfnp989mfivefiverpzrjs   | 989    | 99          | 98955   |

1000 rows × 4 columns
:END:

Now, construct the calibration value as before...

#+BEGIN_SRC jupyter-python
txt['calibration2'] = txt.loc[:, 'digits2'].apply(lambda x: int(x[0] + x[-1]))
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                          | digits | calibration | digits2 | calibration2 |
|-----+-------------------------------+--------+-------------+---------+--------------|
| 0   | jjfvnnlfivejj1                | 1      | 11          | 51      | 51           |
| 1   | 6fourfour                     | 6      | 66          | 644     | 64           |
| 2   | ninevbmltwo69                 | 69     | 69          | 9269    | 99           |
| 3   | pcg91vqrfpxxzzzoneightzt      | 91     | 91          | 9118    | 98           |
| 4   | jpprthxgjfive3one1qckhrptpqdc | 31     | 31          | 5311    | 51           |
| ... | ...                           | ...    | ...         | ...     | ...          |
| 995 | 583sevenhjxlqzjgbzxhkcl5      | 5835   | 55          | 58375   | 55           |
| 996 | 81s                           | 81     | 81          | 81      | 81           |
| 997 | 2four3threesxxvlfqfive4       | 234    | 24          | 243354  | 24           |
| 998 | nine6eightsevenzx9twoxc       | 69     | 69          | 968792  | 92           |
| 999 | hmbfjdfnp989mfivefiverpzrjs   | 989    | 99          | 98955   | 95           |

1000 rows × 5 columns
:END:

... and get the correct sum!

#+BEGIN_SRC jupyter-python
txt.loc[:, 'calibration2'].sum()
#+END_SRC

#+RESULTS:
: 55902

** DONE Advent of code 2023 - Tag 1: Trebuchet?! :python:
CLOSED: [2023-12-10 So 23:38]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day01.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 1 - siehe [[https:adventofcode.com/2023/day/1]]

** DONE Advent of code 2023 - Day 2: Cube Conundrum :python:
CLOSED: [2023-12-11 Mo 23:38]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day02.en.md
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 2 - see [[https:adventofcode.com/2023/day/2]]
*** Part 1

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
As you walk, the Elf shows you a small bag and some cubes which are either red,
green, or blue. Each time you play this game, he will hide a secret number of
cubes of each color in the bag, and your goal is to figure out information about
the number of cubes.

To get information, once a bag has been loaded with cubes, the Elf will reach
into the bag, grab a handful of random cubes, show them to you, and then put
them back in the bag. He'll do this a few times per game.

You play several games and record the information from each game (your puzzle
input). Each game is listed with its ID number (like the =11= in =Game 11: ...=)
followed by a semicolon-separated list of subsets of cubes that were revealed
from the bag (like =3 red, 5 green, 4 blue=).

For example, the record of a few games might look like this:
#+end_quote

#+begin_example
Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green
Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue
Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red
Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red
Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green
#+end_example

#+begin_quote
In game 1, three sets of cubes are revealed from the bag (and then put back
again). The first set is 3 blue cubes and 4 red cubes; the second set is 1 red
cube, 2 green cubes, and 6 blue cubes; the third set is only 2 green cubes.

The Elf would first like to know which games would have been possible if the bag
contained *only 12 red cubes, 13 green cubes, and 14 blue cubes*?

In the example above, games 1, 2, and 5 would have been possible if the bag had
been loaded with that configuration. However, game 3 would have been impossible
because at one point the Elf showed you 20 red cubes at once; similarly, game 4
would also have been impossible because the Elf showed you 15 blue cubes at
once. If you add up the IDs of the games that would have been possible, you
get =8=.

Determine which games would have been possible if the bag had been loaded with
only 12 red cubes, 13 green cubes, and 14 blue cubes. *What is the sum of the IDs
of those games*?
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-02-1-aoc.txt][2023-12-02-1-aoc.txt]]

Okay, let's load our python kernel in emacs-jupyter and get coding! First of
all, let's load the input and split the riddle code by colon =:= to extract the
game id and the rest of the code by semicolon =;= to get the number of sets
played in each game.

#+BEGIN_SRC jupyter-python
import pandas as pd
import re

txt = pd.read_table('data/2023-12-02-1-aoc.txt', names=['code'])
txt['id'] = txt.loc[:, 'code'].str.split(':').apply(
    lambda x: int(x[0].strip('Game ')))
txt['code'] = txt.loc[:, 'code'].str.split(':').apply(lambda x: x[1])
# txt['code'] = txt.loc[:, 'code'].str.split(';')
# txt['nsets'] = txt.loc[:, 'code'].apply(lambda x: len(x))
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                                             | id  |
|-----+--------------------------------------------------+-----|
| 0   | 1 green, 1 blue, 1 red; 1 green, 8 red, 7 blu... | 1   |
| 1   | 9 red, 7 green, 3 blue; 15 green, 2 blue, 5 r... | 2   |
| 2   | 3 red, 1 blue, 4 green; 6 red, 3 green, 2 blu... | 3   |
| 3   | 2 blue, 2 green, 19 red; 3 blue, 11 red, 16 g... | 4   |
| 4   | 8 green, 1 red, 12 blue; 10 green, 6 red, 13 ... | 5   |
| ... | ...                                              | ... |
| 95  | 2 red, 2 green, 1 blue; 1 red, 4 green; 1 green  | 96  |
| 96  | 4 red, 5 green; 5 blue, 3 red; 8 blue, 2 gree... | 97  |
| 97  | 1 blue; 2 green, 1 red; 5 red, 2 green; 4 red... | 98  |
| 98  | 6 blue, 5 red, 2 green; 9 red, 1 blue; 2 gree... | 99  |
| 99  | 1 blue, 13 green, 14 red; 11 green, 11 blue, ... | 100 |

100 rows × 2 columns
:END:

Now, let's extract the three colors in different columns with regex. We use the
lookahead assertion ~?=~ to find the respective colours and only exctract the
digits =\d+= coming before. Then we just keep the =max= imum drawn number of cubes
per color, since this is the only information that matters at the moment.

#+BEGIN_SRC jupyter-python
txt['green'] = txt.loc[:, 'code'].apply(
    lambda code: re.findall(r'\d+(?=.green)', code)).apply(
        lambda list: max([int(i) for i in list]))
txt['red'] = txt.loc[:, 'code'].apply(
    lambda code: re.findall(r'\d+(?=.red)', code)).apply(
        lambda list: max([int(i) for i in list]))
txt['blue'] = txt.loc[:, 'code'].apply(
    lambda code: re.findall(r'\d+(?=.blue)', code)).apply(
        lambda list: max([int(i) for i in list]))
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                                             | id  | green | red | blue |
|-----+--------------------------------------------------+-----+-------+-----+------|
| 0   | 1 green, 1 blue, 1 red; 1 green, 8 red, 7 blu... | 1   | 2     | 10  | 10   |
| 1   | 9 red, 7 green, 3 blue; 15 green, 2 blue, 5 r... | 2   | 15    | 10  | 3    |
| 2   | 3 red, 1 blue, 4 green; 6 red, 3 green, 2 blu... | 3   | 4     | 6   | 16   |
| 3   | 2 blue, 2 green, 19 red; 3 blue, 11 red, 16 g... | 4   | 16    | 20  | 18   |
| 4   | 8 green, 1 red, 12 blue; 10 green, 6 red, 13 ... | 5   | 10    | 6   | 14   |
| ... | ...                                              | ... | ...   | ... | ...  |
| 95  | 2 red, 2 green, 1 blue; 1 red, 4 green; 1 green  | 96  | 4     | 2   | 1    |
| 96  | 4 red, 5 green; 5 blue, 3 red; 8 blue, 2 gree... | 97  | 5     | 4   | 8    |
| 97  | 1 blue; 2 green, 1 red; 5 red, 2 green; 4 red... | 98  | 2     | 5   | 2    |
| 98  | 6 blue, 5 red, 2 green; 9 red, 1 blue; 2 gree... | 99  | 2     | 9   | 11   |
| 99  | 1 blue, 13 green, 14 red; 11 green, 11 blue, ... | 100 | 13    | 15  | 11   |

100 rows × 5 columns
:END:

Lastly, we just filter the DataFrame to only include games where all drawn cubes
were below or equal the number of cubes in the game and sum the result!

#+BEGIN_SRC jupyter-python
txt['id'][(txt['green'] < 14) & (txt['red'] < 13) & (txt['blue'] < 15)].sum()
#+END_SRC

#+RESULTS:
: 3035

*** Part 2

#+begin_details
#+begin_summary
First, let's get the instruction from the second part:
#+end_summary
#+begin_quote
As you continue your walk, the Elf poses a second question: in each game you
played, what is the fewest number of cubes of each color that could have been in
the bag to make the game possible?

Again consider the example games from earlier:
#+end_quote

#+begin_example
Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green
Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue
Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red
Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red
Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green
#+end_example

#+begin_quote
- In game 1, the game could have been played with as few as 4 red, 2 green, and
  6 blue cubes. If any color had even one fewer cube, the game would have been
  impossible.
- Game 2 could have been played with a minimum of 1 red, 3 green, and 4 blue
  cubes.
- Game 3 must have been played with at least 20 red, 13 green, and 6 blue cubes.
- Game 4 required at least 14 red, 3 green, and 15 blue cubes.
- Game 5 needed no fewer than 6 red, 3 green, and 2 blue cubes in the bag.

The *power* of a set of cubes is equal to the numbers of red, green, and blue
cubes multiplied together. The power of the minimum set of cubes in game 1
is 48. In games 2-5 it was 12, 1560, 630, and 36, respectively. Adding up these
five powers produces the sum 2286.

For each game, find the minimum set of cubes that must have been present. *What
is the sum of the power of these sets?*
#+end_quote
#+end_details

Luckily, this task is made trivial by the approach we have taken before. We just
have to multiply the =green=, =red= and =blue= columns:

#+BEGIN_SRC jupyter-python
txt['power'] = txt.loc[:, 'green'] * txt.loc[:, 'blue'] * txt.loc[:, 'red']
txt
#+END_SRC

#+RESULTS:
:RESULTS:
|     | code                                             | id  | green | red | blue | power |
|-----+--------------------------------------------------+-----+-------+-----+------+-------|
| 0   | 1 green, 1 blue, 1 red; 1 green, 8 red, 7 blu... | 1   | 2     | 10  | 10   | 200   |
| 1   | 9 red, 7 green, 3 blue; 15 green, 2 blue, 5 r... | 2   | 15    | 10  | 3    | 450   |
| 2   | 3 red, 1 blue, 4 green; 6 red, 3 green, 2 blu... | 3   | 4     | 6   | 16   | 384   |
| 3   | 2 blue, 2 green, 19 red; 3 blue, 11 red, 16 g... | 4   | 16    | 20  | 18   | 5760  |
| 4   | 8 green, 1 red, 12 blue; 10 green, 6 red, 13 ... | 5   | 10    | 6   | 14   | 840   |
| ... | ...                                              | ... | ...   | ... | ...  | ...   |
| 95  | 2 red, 2 green, 1 blue; 1 red, 4 green; 1 green  | 96  | 4     | 2   | 1    | 8     |
| 96  | 4 red, 5 green; 5 blue, 3 red; 8 blue, 2 gree... | 97  | 5     | 4   | 8    | 160   |
| 97  | 1 blue; 2 green, 1 red; 5 red, 2 green; 4 red... | 98  | 2     | 5   | 2    | 20    |
| 98  | 6 blue, 5 red, 2 green; 9 red, 1 blue; 2 gree... | 99  | 2     | 9   | 11   | 198   |
| 99  | 1 blue, 13 green, 14 red; 11 green, 11 blue, ... | 100 | 13    | 15  | 11   | 2145  |

100 rows × 6 columns
:END:

And for this one, the sum is:

#+BEGIN_SRC jupyter-python
txt['power'].sum()
#+END_SRC

#+RESULTS:
: 66027

** DONE Advent of code 2023 - Tag 2: Würfelrätsel :python:
CLOSED: [2023-12-11 Mo 23:38]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day02.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 2 - siehe [[https:adventofcode.com/2023/day/2]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.
** DONE Advent of code 2023 - Day 3: Gear Ratios :python:
CLOSED: [2023-12-18 Mo 01:01]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day03.en.md
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 3 - see [[https:adventofcode.com/2023/day/3]]
*** Part 1

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
The engine schematic (your puzzle input) consists of a visual representation of
the engine. There are lots of numbers and symbols you don't really understand,
but apparently *any number adjacent to a symbol*, even diagonally, is a "part
number" and should be included in your sum. (Periods (=.=) do not count as a
symbol.)

Here is an example engine schematic:
#+end_quote

#+begin_example
467..114..
...*......
..35..633.
......#...
617*......
.....+.58.
..592.....
......755.
...$.*....
.664.598..
#+end_example

#+begin_quote
In this schematic, two numbers are not part numbers because they are not
adjacent to a symbol: =114= (top right) and =58= (middle right). Every other
number is adjacent to a symbol and so is a part number; their sum is =4361=.

Of course, the actual engine schematic is much larger. *What is the sum of all of
the part numbers in the engine schematic*?
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-03-1-aoc.txt][2023-12-03-1-aoc.txt]]

Okay, let's first get the input as a =numpy= character array

#+begin_src jupyter-python
import numpy as np
import pandas as pd
import sys
import matplotlib.pyplot as plt
from scipy import ndimage as ndi
np.set_printoptions(threshold=sys.maxsize)

txt = pd.read_table('data/2023-12-03-1-aoc.txt', names=['code'])
arr = np.chararray((txt.size, txt.size), unicode=True)

txt['code'] = txt.loc[:, 'code'].apply(lambda x: [i for i in x])

for i, code in enumerate(txt['code']):
    arr[i, :] = code

print((arr[:15, :15]))
#+end_src

#+RESULTS:
#+begin_example
[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.']
 ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '5' '3' '.' '4']
 ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '*' '.' '.' '.' '.']
 ['.' '.' '.' '.' '.' '.' '.' '7' '2' '6' '.' '.' '.' '.' '.']
 ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '9' '5']
 ['.' '.' '.' '.' '.' '.' '.' '7' '3' '8' '.' '.' '.' '*' '.']
 ['.' '7' '4' '.' '.' '.' '.' '.' '.' '.' '.' '.' '3' '6' '6']
 ['.' '.' '.' '*' '1' '2' '6' '.' '.' '.' '.' '.' '.' '.' '.']
 ['.' '.' '.' '.' '.' '.' '.' '.' '3' '3' '1' '/' '.' '.' '9']
 ['.' '.' '.' '.' '/' '.' '.' '.' '.' '.' '.' '.' '.' '.' '*']
 ['.' '.' '.' '.' '9' '5' '3' '.' '.' '.' '.' '3' '5' '5' '.']
 ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.']
 ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.' '.']
 ['.' '6' '8' '5' '.' '.' '.' '.' '*' '.' '.' '.' '.' '7' '0']
 ['.' '.' '.' '.' '.' '.' '.' '.' '.' '9' '3' '8' '.' '.' '*']]
/tmp/ipykernel_18336/87086526.py:9: DeprecationWarning: `np.chararray` is deprecated and will be removed from the main namespace in the future. Use an array with a string or bytes dtype instead.
  arr = np.chararray((txt.size, txt.size), unicode=True)
#+end_example

Now extract symbols, digits and the empty space. We use the =numpy= character
methods for that. This way, we create a binary mask for all *digits* and a
binary mask for all *empty* space (=.=). The *symbols* are then every character
which is neither.

#+begin_src jupyter-python :file 2023-12-03-2-aoc.png
digits = np.char.isdigit(arr)
empty = np.char.endswith(arr, '.')
symbols = ~(digits | empty)

# just for visualization
plt.figure(figsize=(16, 5))
plt.subplot(131, title='symbols').matshow(symbols)
plt.subplot(132, title='digits').matshow(digits)
plt.subplot(133, title='empty').matshow(empty)
plt.show()
#+end_src

#+RESULTS:
[[file:data/2023-12-03-2-aoc.png]]

Now we use the image processing technique of dilation on the =symbols= mask. So
that we get a new mask which covers the surroundings of all symbols. We use this
afterwards to check if the digits are near a symbol.

#+begin_src jupyter-python :file 2023-12-03-3-aoc.png
struct = ((1, 1, 1), (1, 1, 1), (1, 1, 1))
dilate = ndi.binary_dilation(symbols, structure=struct)
plt.figure(figsize=(10, 6))
plt.subplot(121, title='symbols').matshow(symbols[:15, :15])
plt.subplot(122, title='symbols dilated').matshow(dilate[:15, :15])
plt.show()
#+end_src

#+RESULTS:
[[file:data/2023-12-03-3-aoc.png]]

Creating this masks as before could be understood as a *binary segmentation*, as
each element in our mask is either =True= or =False=. To extract the single
digits, we'll convert the binary digits segmentation into a *instance
segmentation*, where each connected segment has an own index.

#+begin_src jupyter-python :file 2023-12-03-4-aoc.png
markers, num_features = ndi.label(digits)
plt.figure(figsize=(10, 6))
plt.subplot(121, title='binary segmentation').matshow(
    digits[:15, :15])
plt.subplot(122, title='instance segmentation').matshow(
    markers[:15, :15], cmap='gnuplot')
plt.show()
#+end_src

#+RESULTS:
[[file:data/2023-12-03-4-aoc.png]]

Now, for each instance, we check if the dilated binary mask overlaps with the
instance and if yes, we extract the number.

#+begin_src jupyter-python
numbers = [int(''.join(arr[markers == i]))
           for i in range(1, num_features+1)
           if np.any((markers == i) & dilate)]
#+end_src

#+RESULTS:

Then, we just sum up:

#+begin_src jupyter-python
sum(numbers)
#+end_src

#+RESULTS:
: 527364

*** Part 2

#+begin_details
#+begin_summary
Let's first read the second task!
#+end_summary
#+begin_quote
The missing part wasn't the only issue - one of the gears in the engine is
wrong. A gear is any * symbol that is adjacent to exactly two part numbers. Its
gear ratio is the result of multiplying those two numbers together.

This time, you need to find the gear ratio of every gear and add them all up so
that the engineer can figure out which gear needs to be replaced.

Consider the same engine schematic again:The missing part wasn't the only
issue - one of the gears in the engine is wrong. A gear is any * symbol that is
adjacent to exactly two part numbers. Its gear ratio is the result of
multiplying those two numbers together.

This time, you need to find the gear ratio of every gear and add them all up so
that the engineer can figure out which gear needs to be replaced.

Consider the same engine schematic again:
#+end_quote

#+begin_example
467..114..
...*......
..35..633.
......#...
617*......
.....+.58.
..592.....
......755.
...$.*....
.664.598..
#+end_example

#+begin_quote
In this schematic, there are *two* gears. The first is in the top left; it has
part numbers =467= and =35=, so its gear ratio is =16345=. The second gear is in
the lower right; its gear ratio is =451490=. (The =*= adjacent to =617= is not a
gear because it is only adjacent to one part number.) Adding up all of the gear
ratios produces =467835=.

*What is the sum of all of the gear ratios in your engine schematic?*
#+end_quote
#+end_details

We'll use the same method as before, but this time only extract =*= and create
the instance segmentation *before* the dilation. Why? Because when we dilate
first, we could merge two independent gears into one instance.

#+begin_src jupyter-python :file 2023-12-03-5-aoc.png
gear = np.char.endswith(arr, '*')
gear_markers, gear_num = ndi.label(gear)

plt.figure(figsize=(10, 6))
plt.subplot(131, title='all symbols dilated').matshow(
    symbols[:15, :15])
plt.subplot(132, title='gears').matshow(
    gear[:15, :15])
plt.subplot(133, title='gears instances').matshow(
    gear_markers[:15, :15], cmap='gnuplot')
plt.show()
#+end_src

#+RESULTS:
[[file:data/2023-12-03-5-aoc.png]]

Now, we step through each gear instance, create a mask for that gear, dilate it,
and then step through all digits and check if they are in the gear mask. If we
get two digits in the end, we multiply them to get the gear ratio and save the
ratios to a list.

#+begin_src jupyter-python
gear_ratios = []
for i in range(1, gear_num+1):
    gear_binary = gear_markers == i
    gear_dil = ndi.binary_dilation(gear_binary, structure=struct)
    part_numbers = [int(''.join(arr[markers == j]))
                    for j in range(1, num_features+1)
                    if np.any((markers == j) & gear_dil)]
    if len(part_numbers) == 2:
        gear_ratios.append(part_numbers[0] * part_numbers[1])
#+end_src

#+RESULTS:

Now, we just sum the output again:
#+begin_src jupyter-python
sum(gear_ratios)
#+end_src

#+RESULTS:
: 79026871

** DONE Advent of code 2023 - Tag 3: Getriebeübersetzungen :python:
CLOSED: [2023-12-18 Mo 01:01]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day03.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 3 - siehe [[https:adventofcode.com/2023/day/3]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.
** DONE Advent of code 2023 - Day 4: Scratchcards :python:
CLOSED: [2023-12-19 Di 00:25]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day04.en.md
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 4 - see [[https:adventofcode.com/2023/day/4]]
*** Part 1

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
The Elf leads you over to the pile of colorful cards. There, you discover dozens
of scratchcards, all with their opaque covering already scratched off. Picking
one up, it looks like each card has two lists of numbers separated by a vertical
bar (=|=): a list of *winning numbers* and then a list of *numbers you have*.
You organize the information into a table (your puzzle input).

As far as the Elf has been able to figure out, you have to figure out which of
the *numbers you have* appear in the list of *winning numbers*. The first match
makes the card worth *one point* and each match after the first *doubles* the
point value of that card.

For example:
#+end_quote

#+begin_example
Card 1: 41 48 83 86 17 | 83 86  6 31 17  9 48 53
Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19
Card 3:  1 21 53 59 44 | 69 82 63 72 16 21 14  1
Card 4: 41 92 73 84 69 | 59 84 76 51 58  5 54 83
Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36
Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11
#+end_example

#+begin_quote
In the above example, card 1 has five winning numbers (=41=, =48=, =83=, =86=,
and =17=) and eight numbers you have (=83=, =86=, =6=, =31=, =17=, =9=, =48=,
and =53=). Of the numbers you have, four of them (=48=, =83=, =17=, and =86=)
are winning numbers! That means card 1 is worth =8= points (1 for the first
match, then doubled three times for each of the three matches after the first).

- Card 2 has two winning numbers (=32= and =61=), so it is worth =2= points.
- Card 3 has two winning numbers (=1= and =21=), so it is worth =2= points.
- Card 4 has one winning number (=84=), so it is worth =1= point.
- Card 5 has no winning numbers, so it is worth no points.
- Card 6 has no winning numbers, so it is worth no points.

So, in this example, the Elf's pile of scratchcards is worth =13= points.

Take a seat in the large pile of colorful cards. *How many points are they worth
in total?*
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-04-1-aoc.txt][2023-12-04-1-aoc.txt]]

Loading this data is very similar to *Day 2* - so let's load the data as we did
there. Our goal is to get =win= and =yours= columns holding the respective
digits which we want to compare. We find the numbers with one or more digits
using the regex =\d+=. And we want them to be in *sets* (not lists), as we can
logically compare sets in Python.

#+begin_src jupyter-python
import pandas as pd
import re

txt = pd.read_table('data/2023-12-04-1-aoc.txt', names=['win'])
txt['id'] = txt.loc[:, 'win'].str.split(':').apply(
    lambda x: int(x[0].strip('Card ')))
txt['win'] = (txt.loc[:, 'win']
              .str.split(':').apply(lambda x: x[1]))
txt['yours'] = (txt.loc[:, 'win']
                .str.split('|')
                .apply(lambda x: x[1])
                # get a list of only the numbers / digits
                .apply(lambda x: re.findall(r'\d+', x))
                # convert the list of strings to a set of integers
                .apply(lambda x: set([int(i) for i in x])))
txt['win'] = (txt.loc[:, 'win']
              .str.split('|')
              .apply(lambda x: x[0])
              .apply(lambda x: re.findall(r'\d+', x))
              .apply(lambda x: set([int(i) for i in x])))

txt
#+end_src

#+RESULTS:
:RESULTS:
|     | win                                      | id  | yours                                             |
|-----+------------------------------------------+-----+---------------------------------------------------|
| 0   | {32, 36, 7, 9, 10, 12, 82, 85, 95, 31}   | 1   | {2, 7, 9, 10, 12, 14, 21, 22, 23, 24, 31, 32, ... |
| 1   | {35, 76, 16, 82, 19, 22, 88, 59, 60, 95} | 2   | {7, 8, 12, 16, 19, 22, 26, 28, 35, 38, 44, 51,... |
| 2   | {1, 70, 11, 78, 48, 19, 52, 88, 28, 94}  | 3   | {3, 4, 8, 17, 18, 19, 24, 31, 34, 45, 52, 54, ... |
| 3   | {65, 2, 72, 28, 14, 16, 55, 91, 92, 62}  | 4   | {3, 4, 6, 7, 8, 9, 15, 30, 33, 35, 47, 49, 51,... |
| 4   | {38, 41, 75, 77, 50, 24, 94, 60, 61, 30} | 5   | {1, 2, 4, 5, 6, 7, 9, 10, 14, 17, 21, 29, 47, ... |
| ... | ...                                      | ... | ...                                               |
| 213 | {97, 98, 39, 41, 43, 12, 13, 19, 93, 95} | 214 | {5, 10, 17, 20, 28, 29, 33, 34, 36, 50, 51, 52... |
| 214 | {97, 35, 69, 40, 74, 45, 20, 21, 62, 31} | 215 | {1, 8, 15, 17, 18, 25, 30, 33, 42, 44, 47, 52,... |
| 215 | {33, 70, 71, 12, 78, 17, 51, 86, 60, 94} | 216 | {7, 8, 9, 10, 22, 29, 37, 39, 41, 43, 46, 47, ... |
| 216 | {98, 67, 68, 38, 70, 39, 72, 77, 45, 21} | 217 | {8, 21, 22, 25, 26, 31, 37, 41, 42, 48, 54, 57... |
| 217 | {34, 9, 44, 78, 79, 16, 17, 19, 55, 92}  | 218 | {1, 4, 20, 21, 27, 38, 39, 40, 41, 45, 46, 52,... |

218 rows × 3 columns
:END:

Now, we get the [[https://en.wikipedia.org/wiki/Logical_conjunction][logical conjunction]] of =win= and =yours=, these are our winning
numbers. Then, the number of wins is converted to points - for all number of
wins bigger than 1, we can get the points by =2**(n_wins-1)=.

#+begin_src jupyter-python
txt['n_wins'] = txt.apply(
    lambda row: len(row.loc['win'] & row.loc['yours']), axis=1)
txt['points'] = txt.loc[:, 'n_wins'].apply(
    lambda x: 2**(x-1) if x > 1 else x)

txt.loc[:, ['win', 'n_wins', 'points']]
#+end_src

#+RESULTS:
:RESULTS:
|     | win                                      | n_wins | points |
|-----+------------------------------------------+--------+--------|
| 0   | {32, 36, 7, 9, 10, 12, 82, 85, 95, 31}   | 10     | 512    |
| 1   | {35, 76, 16, 82, 19, 22, 88, 59, 60, 95} | 10     | 512    |
| 2   | {1, 70, 11, 78, 48, 19, 52, 88, 28, 94}  | 5      | 16     |
| 3   | {65, 2, 72, 28, 14, 16, 55, 91, 92, 62}  | 0      | 0      |
| 4   | {38, 41, 75, 77, 50, 24, 94, 60, 61, 30} | 0      | 0      |
| ... | ...                                      | ...    | ...    |
| 213 | {97, 98, 39, 41, 43, 12, 13, 19, 93, 95} | 0      | 0      |
| 214 | {97, 35, 69, 40, 74, 45, 20, 21, 62, 31} | 0      | 0      |
| 215 | {33, 70, 71, 12, 78, 17, 51, 86, 60, 94} | 2      | 2      |
| 216 | {98, 67, 68, 38, 70, 39, 72, 77, 45, 21} | 1      | 1      |
| 217 | {34, 9, 44, 78, 79, 16, 17, 19, 55, 92}  | 0      | 0      |

218 rows × 3 columns
:END:

Then, we just sum up:

#+begin_src jupyter-python
sum(txt.loc[:, 'points'])
#+end_src

#+RESULTS:
: 25004

*** Part 2

#+begin_details
#+begin_summary
Let's read the task of part 2!
#+end_summary

#+begin_quote
There's no such thing as "points". Instead, scratchcards only cause you to *win
more scratchcards* equal to the number of winning numbers you have.

Specifically, you win *copies* of the scratchcards below the winning card equal to
the number of matches. So, if card 10 were to have 5 matching numbers, you would
win one copy each of cards 11, 12, 13, 14, and 15.

Copies of scratchcards are scored like normal scratchcards and have the *same
card number* as the card they copied. So, if you win a copy of card 10 and it
has 5 matching numbers, it would then win a copy of the same cards that the
original card 10 won: cards 11, 12, 13, 14, and 15. This process repeats until
none of the copies cause you to win any more cards. (Cards will never make you
copy a card past the end of the table.)

This time, the above example goes differently:
#+end_quote

#+begin_example
Card 1: 41 48 83 86 17 | 83 86  6 31 17  9 48 53
Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19
Card 3:  1 21 53 59 44 | 69 82 63 72 16 21 14  1
Card 4: 41 92 73 84 69 | 59 84 76 51 58  5 54 83
Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36
Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11
#+end_example

#+begin_quote
- Card 1 has four matching numbers, so you win one copy each of the next four
  cards: cards 2, 3, 4, and 5.
- Your original card 2 has two matching numbers, so you win one copy each of
  cards 3 and 4.
- Your copy of card 2 also wins one copy each of cards 3 and 4.
- Your four instances of card 3 (one original and three copies) have two
  matching numbers, so you win *four* copies each of cards 4 and 5.
- Your eight instances of card 4 (one original and seven copies) have one
  matching number, so you win *eight* copies of card 5.
- Your fourteen instances of card 5 (one original and thirteen copies) have no
  matching numbers and win no more cards.

Once all of the originals and copies have been processed, you end up with =1=
instance of card 1, =2= instances of card 2, =4= instances of card 3, =8=
instances of card 4, =14= instances of card 5, and =1= instance of card 6. In
total, this example pile of scratchcards causes you to ultimately have =30=
scratchcards!

Process all of the original and copied scratchcards until no more scratchcards
are won. Including the original set of scratchcards, *how many total scratchcards
do you end up with?*
#+end_quote
#+end_details

We will use the  =n_wins= column we created before and go from there. We step
through each Game. Each *current game* gets +1 card. Then, we step through the
number of *next games* depending on our =n_wins=. Each of these gets added the
card number of the *current game*.

#+begin_src jupyter-python
txt['cards'] = 0

for i, nwin in enumerate(txt.loc[:, 'n_wins']):
    txt.loc[i, 'cards'] += 1
    for j in range(1, nwin+1):
        txt.loc[i+j, 'cards'] += txt.loc[i, 'cards']

txt.loc[:, ['n_wins', 'cards']]
#+end_src

#+RESULTS:
:RESULTS:
|     | n_wins | cards |
|-----+--------+-------|
| 0   | 10     | 1     |
| 1   | 10     | 2     |
| 2   | 5      | 4     |
| 3   | 0      | 8     |
| 4   | 0      | 8     |
| ... | ...    | ...   |
| 213 | 0      | 9608  |
| 214 | 0      | 8927  |
| 215 | 2      | 8927  |
| 216 | 1      | 12636 |
| 217 | 0      | 21564 |

218 rows × 2 columns
:END:

Now, we just sum the output again:

#+begin_src jupyter-python
sum(txt['cards'])
#+end_src

#+RESULTS:
: 14427616

** DONE Advent of code 2023 - Tag 4: Rubbelkarten :python:
CLOSED: [2023-12-19 Di 00:25]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day04.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 4 - siehe [[https:adventofcode.com/2023/day/4]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.
** DONE Advent of code 2023 - Day 5: If You Give A Seed A Fertilizer :python:
CLOSED: [2023-12-30 Sa 01:10]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day05.en.md
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 5 - see [[https:adventofcode.com/2023/day/5]]

Update [2023-12-31 So]:
- substitute =get_generator()= (own implementation) with =range()= (Python inbuilt)
- improve grid search so that it goes through all location ranges, still
  starting with the lowest range
*** Part 1

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
The almanac (your puzzle input) lists all of the seeds that need to be planted.
It also lists what type of soil to use with each kind of seed, what type of
fertilizer to use with each kind of soil, what type of water to use with each
kind of fertilizer, and so on. Every type of seed, soil, fertilizer and so on is
identified with a number, but numbers are reused by each category - that is,
soil =123= and fertilizer =123= aren't necessarily related to each other.

For example:
#+end_quote

#+begin_example
seeds: 79 14 55 13

seed-to-soil map:
50 98 2
52 50 48

soil-to-fertilizer map:
0 15 37
37 52 2
39 0 15

fertilizer-to-water map:
49 53 8
0 11 42
42 0 7
57 7 4

water-to-light map:
88 18 7
18 25 70

light-to-temperature map:
45 77 23
81 45 19
68 64 13

temperature-to-humidity map:
0 69 1
1 0 69

humidity-to-location map:
60 56 37
56 93 4
#+end_example

#+begin_quote
The almanac starts by listing which seeds need to be planted: seeds =79=, =14=,
=55=, and =13=.

The rest of the almanac contains a list of *maps* which describe how to convert
numbers from a *source category* into numbers in a *destination category*. That
is, the section that starts with =seed-to-soil map=: describes how to convert a
*seed number* (the source) to a *soil number* (the destination). This lets the
gardener and his team know which soil to use with which seeds, which water to
use with which fertilizer, and so on.

Rather than list every source number and its corresponding destination number
one by one, the maps describe entire *ranges* of numbers that can be converted.
Each line within a map contains three numbers: the *destination range start*,
the *source range start*, and the *range length*.

Consider again the example =seed-to-soil map=:

=50 98 2
52 50 48=

The first line has a *destination range start* of =50=, a *source range start*
of =98=, and a *range length* of =2=. This line means that the source range
starts at =98= and contains two values: =98= and =99=. The destination range is
the same length, but it starts at =50=, so its two values are =50= and =51=.
With this information, you know that seed number =98= corresponds to soil number
=50= and that seed number =99= corresponds to soil number =51=.
o
The second line means that the source range starts at =50= and contains =48=
values: =50=, =51=, ..., =96=, =97=. This corresponds to a destination range
starting at =52= and also containing =48= values: =52=, =53=, ..., =98=, =99=.
So, seed number =53= corresponds to soil number =55=.

Any source numbers that *aren't mapped* correspond to the *same* destination
number. So, seed number =10= corresponds to soil number =10=.

So, the entire list of seed numbers and their corresponding soil numbers looks
like this:
#+end_quote

#+begin_example
seed  soil
0     0
1     1
...   ...
48    48
49    49
50    52
51    53
...   ...
96    98
97    99
98    50
99    51
#+end_example

#+begin_quote
With this map, you can look up the soil number required for each initial seed
number:

- Seed number =79= corresponds to soil number =81=.
- Seed number =14= corresponds to soil number =14=.
- Seed number =55= corresponds to soil number =57=.
- Seed number =13= corresponds to soil number =13=.

The gardener and his team want to get started as soon as possible, so they'd
like to know the closest location that needs a seed. Using these maps, find *the
lowest location number that corresponds to any of the initial seeds*. To do
this, you'll need to convert each seed number through other categories until you
can find its corresponding *location number*. In this example, the corresponding
types are:

- Seed =79=, soil =81=, fertilizer =81=, water =81=, light =74=, temperature
  =78=, humidity =78=, location =82=.
- Seed =14=, soil =14=, fertilizer =53=, water =49=, light =42=, temperature
  =42=, humidity =43=, location =43=.
- Seed =55=, soil =57=, fertilizer =57=, water =53=, light =46=, temperature
  =82=, humidity =82=, location =86=.
- Seed =13=, soil =13=, fertilizer =52=, water =41=, light =34=, temperature
  =34=, humidity =35=, location =35=.

So, the lowest location number in this example is =35=.

*What is the lowest location number that corresponds to any of the initial seed
 numbers?*
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-05-1-aoc.txt][2023-12-05-1-aoc.txt]]

Wow, this task is a mouthful...

Let's start slowly and load the data. Our input text document contains several
maps, which are clearly separated and have a title (=seed-to-soil map= etc). So
we can tell pandas where each map starts and give each map a dataframe. I got
the values for the =skiprows= and =nrows= argument by looking at the input file
and... counting
:)

#+begin_src jupyter-python
import pandas as pd
import sys

seeds = pd.read_table('data/2023-12-05-1-aoc.txt', nrows=1, sep=' ',
                      header=None, index_col=0)
seeds = seeds.values.flatten()

map_opt = {'filepath_or_buffer': 'data/2023-12-05-1-aoc.txt',
           'header': None, 'sep': ' ', 'dtype': 'Int64',
           'names': ['dest_start', 'src_start', 'range']}

seed_soil = pd.read_table(skiprows=3, nrows=23, **map_opt)
soil_fert = pd.read_table(skiprows=28, nrows=9, **map_opt)
fert_water = pd.read_table(skiprows=39, nrows=20, **map_opt)
water_light = pd.read_table(skiprows=61, nrows=40, **map_opt)
light_temp = pd.read_table(skiprows=103, nrows=36, **map_opt)
temp_humi = pd.read_table(skiprows=141, nrows=35, **map_opt)
humi_loc = pd.read_table(skiprows=178, nrows=26, **map_opt)

maps = (seed_soil, soil_fert, fert_water, water_light, light_temp,
        temp_humi, humi_loc)

print('seeds are just a numpy array:')
display(seeds)
print('The "humidity-to-location" map as an example:')
humi_loc
  #+end_src

#+RESULTS:
:RESULTS:
: seeds are just a numpy array:
: array([3169137700,  271717609, 3522125441,   23376095, 1233948799,
:         811833837,  280549587,  703867355,  166086528,   44766996,
:        2326968141,   69162222, 2698492851,   14603069, 2755327667,
:         348999531, 2600461189,   92332846, 1054656969,  169099767])The "humidity-to-location" map as an example:
|    | dest_start | src_start  | range     |
|----+------------+------------+-----------|
| 0  | 3490144003 | 1623866227 | 218040905 |
| 1  | 1709610578 | 1620839197 | 3027030   |
| 2  | 105449249  | 586389428  | 113279526 |
| 3  | 1899604338 | 2167886292 | 348178199 |
| 4  | 1712637608 | 2678624215 | 186966730 |
| 5  | 218728775  | 0          | 245776251 |
| 6  | 2472992580 | 923734334  | 143670388 |
| 7  | 2616662968 | 3670169885 | 15297294  |
| 8  | 2247782537 | 1395629154 | 225210043 |
| 9  | 0          | 480940179  | 105449249 |
| 10 | 4113852846 | 3959729057 | 159909096 |
| 11 | 3322784653 | 1067404722 | 167359350 |
| 12 | 923734334  | 4119638153 | 175329143 |
| 13 | 1534964496 | 2516064491 | 162559724 |
| 14 | 2631960262 | 3496028440 | 140849733 |
| 15 | 2862695906 | 1234764072 | 97988355  |
| 16 | 1697524220 | 3636878173 | 12086358  |
| 17 | 2985646048 | 1332752427 | 62876727  |
| 18 | 1099063477 | 2970241510 | 435901019 |
| 19 | 4009202281 | 2865590945 | 104650565 |
| 20 | 2960684261 | 2142924505 | 24961787  |
| 21 | 2772809995 | 3406142529 | 89885911  |
| 22 | 4273761942 | 3648964531 | 21205354  |
| 23 | 3708184908 | 1841907132 | 301017373 |
| 24 | 464505026  | 245776251  | 235163928 |
| 25 | 3048522775 | 3685467179 | 274261878 |
:END:

My first attempt was to actually construct ranges like in the example above,
mapping out all possible sources and destinations. Python quickly informed me
that even constructing one =pandas.Series= with =int64= values mapping seeds to
soil would cost 64GB memory - not the best solution.

So we take a different approach. For convenience, let's add a =src_end= and a
=dest_end= column to our maps:


#+begin_src jupyter-python
for df in maps:
    df['src_end'] = df.loc[:, 'src_start'] + df.loc[:, 'range']
    df['dest_end'] = df.loc[:, 'dest_start'] + df.loc[:, 'range']

print('Again the "humidity-to-location" map as an example:')
humi_loc
#+end_src

#+RESULTS:
:RESULTS:
: Again the "humidity-to-location" map as an example:
|    | dest_start | src_start  | range     | src_end    | dest_end   |
|----+------------+------------+-----------+------------+------------|
| 0  | 3490144003 | 1623866227 | 218040905 | 1841907132 | 3708184908 |
| 1  | 1709610578 | 1620839197 | 3027030   | 1623866227 | 1712637608 |
| 2  | 105449249  | 586389428  | 113279526 | 699668954  | 218728775  |
| 3  | 1899604338 | 2167886292 | 348178199 | 2516064491 | 2247782537 |
| 4  | 1712637608 | 2678624215 | 186966730 | 2865590945 | 1899604338 |
| 5  | 218728775  | 0          | 245776251 | 245776251  | 464505026  |
| 6  | 2472992580 | 923734334  | 143670388 | 1067404722 | 2616662968 |
| 7  | 2616662968 | 3670169885 | 15297294  | 3685467179 | 2631960262 |
| 8  | 2247782537 | 1395629154 | 225210043 | 1620839197 | 2472992580 |
| 9  | 0          | 480940179  | 105449249 | 586389428  | 105449249  |
| 10 | 4113852846 | 3959729057 | 159909096 | 4119638153 | 4273761942 |
| 11 | 3322784653 | 1067404722 | 167359350 | 1234764072 | 3490144003 |
| 12 | 923734334  | 4119638153 | 175329143 | 4294967296 | 1099063477 |
| 13 | 1534964496 | 2516064491 | 162559724 | 2678624215 | 1697524220 |
| 14 | 2631960262 | 3496028440 | 140849733 | 3636878173 | 2772809995 |
| 15 | 2862695906 | 1234764072 | 97988355  | 1332752427 | 2960684261 |
| 16 | 1697524220 | 3636878173 | 12086358  | 3648964531 | 1709610578 |
| 17 | 2985646048 | 1332752427 | 62876727  | 1395629154 | 3048522775 |
| 18 | 1099063477 | 2970241510 | 435901019 | 3406142529 | 1534964496 |
| 19 | 4009202281 | 2865590945 | 104650565 | 2970241510 | 4113852846 |
| 20 | 2960684261 | 2142924505 | 24961787  | 2167886292 | 2985646048 |
| 21 | 2772809995 | 3406142529 | 89885911  | 3496028440 | 2862695906 |
| 22 | 4273761942 | 3648964531 | 21205354  | 3670169885 | 4294967296 |
| 23 | 3708184908 | 1841907132 | 301017373 | 2142924505 | 4009202281 |
| 24 | 464505026  | 245776251  | 235163928 | 480940179  | 699668954  |
| 25 | 3048522775 | 3685467179 | 274261878 | 3959729057 | 3322784653 |
:END:

Now we actually compute the mapping. For each seed, we go through all mappings
and in each mapping we go through each row. We find the row which contains the
mapping and exctract the destination, which is the source for the next map until
we reach the last map which gives us the locations.

- Approach 1: =df.itertuples()= is a convenient way to step through a
  =pandas.DataFrame= in this example. It is faster than =df.iterrows()= and
  returns the row as a =NamedTuple= -  nice!

- Approach 2: I actually wondered if it would be faster to get all maps in one
  =pd.DataFrame= and then iterate through the mappings. To test this let's
  construct a new DataFrame =maps_df= which contains all =maps=. Since the maps
  have different lengths it is important to cast the datatype to =Int64=, which
  is short for =pd.Int64Dtype()= and keeps values as integers, even if =NA=
  values are in the same column.

- Approach 3: A third alternative I tested (not shown here) was to check if a
  value is in a Python =range= with the =in= operator as in: =if 3 in
  range(5):...= . This was way too slow.

#+begin_src jupyter-python
# mapping version 1
def get_location(seed):
    current = seed
    for df in maps:
        current_map = [row
                       for row in df.itertuples()
                       if ((current > row.src_start)
                           and (current < row.src_end))]
        if len(current_map) == 0:
            pass
        elif len(current_map) == 1:
            current = (current_map[0].dest_start
                       + (current - current_map[0].src_start))
        else:
            raise ValueError('This should not happen!')
    return current

# mapping version 2 - around 10 times slower
# you need to rename the maps_df columns so that they have a unique id
# e.g. 'src_start_1', 'src_start_2' etc

# maps_df = pd.concat(maps, axis='columns')

# def get_dest(i, src):
#     return (maps_df[(src > maps_df.loc[:, f'src_start_{i}']) &
#                     (src < maps_df.loc[:, f'src_end_{i}'])]
#             .loc[:, f'dest_start_{i}']
#             .iloc[0])

# def get_location2(seed):
#     dest = seed
#     i = 1
#     while i < 7:
#         dest = get_dest(i, dest)
#         i += 1
#     return dest

%timeit get_location(seeds[0])
#+end_src

#+RESULTS:
: 1.98 ms ± 72 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)

Now let's get a list of locations:

#+begin_src jupyter-python
locations = [get_location(s) for s in seeds]
locations
#+end_src

#+RESULTS:
| 2493982655 | 3209845376 | 3992357533 | 4163131463 | 4104485616 | 1952252479 | 3218677354 | 388071289 | 2181441450 | 2594336315 | 4049507670 | 2084517144 | 3119633635 | 428978312 | 3518771991 | 3704555655 | 953918455 | 2107687768 | 3448046330 | 2184454689 |

Lastly, just get the minimum of all location values.

#+begin_src jupyter-python
  min(locations)
#+end_src

#+RESULTS:
: 388071289

*** Part 2

#+begin_details
#+begin_summary
Let's read the task of part 2!
#+end_summary

#+begin_quote
Everyone will starve if you only plant such a small number of seeds. Re-reading
the almanac, it looks like the =seeds:= line actually describes *ranges of seed
numbers*.

The values on the initial =seeds:= line come in pairs. Within each pair, the
first value is the *start* of the range and the second value is the *length* of
the range. So, in the first line of the example above:

=seeds: 79 14 55 13=

This line describes two ranges of seed numbers to be planted in the garden. The
first range starts with seed number =79= and contains =14= values: =79=, =80=,
..., =91=, =92=. The second range starts with seed number =55= and contains =13=
values: =55=, =56=, ..., =66=, =67=.

Now, rather than considering four seed numbers, you need to consider a total of
=27= seed numbers.

In the above example, the lowest location number can be obtained from seed
number =82=, which corresponds to soil =84=, fertilizer =84=, water =84=, light
=77=, temperature =45=, humidity =46=, and location =46=. So, the lowest
location number is =46=.

Consider all of the initial seed numbers listed in the ranges on the first line
of the almanac. *What is the lowest location number that corresponds to any of
the initial seed numbers?*
#+end_quote
#+end_details

Let's first construct a dataframe containing the range of seeds:

#+begin_src jupyter-python
seeds_df = pd.DataFrame({'start': seeds[::2],
                         'range': seeds[1::2],
                         'end': seeds[::2] + seeds[1::2]})
print(f'There are {sum(seeds_df.loc[:, "range"]):_} seeds in total')
seeds_df

#+end_src

#+RESULTS:
:RESULTS:
: There are 2_549_759_327 seeds in total
|   | start      | range     | end        |
|---+------------+-----------+------------|
| 0 | 3169137700 | 271717609 | 3440855309 |
| 1 | 3522125441 | 23376095  | 3545501536 |
| 2 | 1233948799 | 811833837 | 2045782636 |
| 3 | 280549587  | 703867355 | 984416942  |
| 4 | 166086528  | 44766996  | 210853524  |
| 5 | 2326968141 | 69162222  | 2396130363 |
| 6 | 2698492851 | 14603069  | 2713095920 |
| 7 | 2755327667 | 348999531 | 3104327198 |
| 8 | 2600461189 | 92332846  | 2692794035 |
| 9 | 1054656969 | 169099767 | 1223756736 |
:END:

Now - I really needed some time to finally realize, that going through all seed
values is really unfeasable. So how do we deal with this problem?

In the end we need the lowest location number - thus our approach is to take
the =humi_loc= map, start with the lowest location number and go up and get the
corresponding seed values. The location of the first seed value which is inside
=seeds_df= is our solution.

So first we rebuild the =get_location= function to a =get_seed= function (we
reverse the =maps= tuple with =maps[::-1]= and switch =src= and =dest=).

#+begin_src jupyter-python :results scalar
def get_seed(location):
    current = location
    for df in maps[::-1]:
        current_map = [row
                       for row in df.itertuples()
                       if ((current >= row.dest_start)
                           and (current < row.dest_end))]
        if len(current_map) == 0:
            pass
        elif len(current_map) == 1:
            current = (current_map[0].src_start
                       + (current - current_map[0].dest_start))
        else:
            raise ValueError('This should not happen!')
    return current
#+end_src

#+RESULTS:

Since the Python 3 =range= function does not store it's contents in memory
(similar to a generator), it is well suited to go through these large ranges.

Lastly, we deal with the sheer amount of possible values by performing a *grid
search*. First, we check every millionth location. After the first match, we
stop this search and check the last million locations before the match with a
finer grid and so on. The last grid is just =1=, so we find our lowest location.

Update: We order our locations from smallest to largest with =sort_values= and
go through them - but the search stops after the first match, since that will be
our lowest location.

#+begin_src jupyter-python
def grid_search(start: int, end: int, grid: list[int]):
    success = False
    for g in grid:
        print(f'Start search with grid={g}')
        for l in range(start, end, g):
            current = get_seed(l)
            if any((current >= seeds_df.loc[:, 'start']) & (current < seeds_df.loc[:, 'end'])):
                print(f'location {l} is the lowest which contains one of the given seeds ({current})')
                start = l - g
                end = l
                success = True
                break
    return success

for row in humi_loc.sort_values('dest_start').itertuples():
    success = grid_search(start=row.dest_start, end=row.dest_end,
                          grid=[1_000_000, 100_000, 1000, 1])
    if success:
        print('Finished search')
        break
#+end_src

#+RESULTS:
: Start search with grid=1000000
: location 85000000 is the lowest which contains one of the given seeds (2605777210)
: Start search with grid=100000
: location 84300000 is the lowest which contains one of the given seeds (2605077210)
: Start search with grid=1000
: location 84207000 is the lowest which contains one of the given seeds (2604984210)
: Start search with grid=1
: location 84206669 is the lowest which contains one of the given seeds (2604983879)
: Finished search

** DONE Advent of code 2023 - Tag 5: Wenn Du Einem Samen Dünger Gibst :python:
CLOSED: [2023-12-30 Sa 01:10]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day05.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 5 - siehe [[https:adventofcode.com/2023/day/5]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.
** DONE Advent of code 2023 - Day 6: Wait For It :python:
CLOSED: [2024-01-04 Do 00:44]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day06.en.md
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 6 - see [[https:adventofcode.com/2023/day/6]]
*** Part 1

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
You manage to sign up as a competitor in the boat races just in time. The
organizer explains that it's not really a traditional race - instead, you will
get a fixed amount of time during which your boat has to travel as far as it
can, and you win if your boat goes the farthest.

As part of signing up, you get a sheet of paper (your puzzle input) that lists
the *time* allowed for each race and also the best *distance* ever recorded in that
race. To guarantee you win the grand prize, you need to make sure you *go farther
in each race* than the current record holder.

The organizer brings you over to the area where the boat races are held. The
boats are much smaller than you expected - they're actually toy boats, each with
a big button on top. Holding down the button charges the boat, and releasing the
button *allows the boat to move*. Boats move faster if their button was held
longer, but time spent holding the button counts against the total race time.
You can only hold the button at the start of the race, and boats don't move
until the button is released.

For example:
#+end_quote

#+begin_example
Time:      7  15   30
Distance:  9  40  200
#+end_example

#+begin_quote
This document describes three races:

- The first race lasts 7 milliseconds. The record distance in this race is 9
  millimeters.
- The second race lasts 15 milliseconds. The record distance in this race is 40
  millimeters.
- The third race lasts 30 milliseconds. The record distance in this race is 200
  millimeters.

Your toy boat has a starting speed of *zero millimeters per millisecond*. For
each whole millisecond you spend at the beginning of the race holding down the
button, the boat's speed increases by *one millimeter per millisecond*.

So, because the first race lasts 7 milliseconds, you only have a few options:

- Don't hold the button at all (that is, hold it for *=0= milliseconds*) at the
  start of the race. The boat won't move; it will have traveled *=0=
  millimeters* by the end of the race.
- Hold the button for *=1= millisecond* at the start of the race. Then, the boat
  will travel at a speed of 1 millimeter per millisecond for 6 milliseconds,
  reaching a total distance traveled of *=6= millimeters*.
- Hold the button for *=2= milliseconds*, giving the boat a speed of 2
  millimeters per millisecond. It will then get 5 milliseconds to move,
  reaching a total distance of *=10= millimeters*.
- Hold the button for *=3= milliseconds*. After its remaining 4 milliseconds of
  travel time, the boat will have gone *=12= millimeters*.
- Hold the button for *=4= milliseconds*. After its remaining 3 milliseconds of
  travel time, the boat will have gone *=12= millimeters*.
- Hold the button for *=5= milliseconds*, causing the boat to travel a total of
  *=10= millimeters*.
- Hold the button for *=6= milliseconds*, causing the boat to travel a total of
  *=6= millimeters*.
- Hold the button for *=7= milliseconds*. That's the entire duration of the
  race. You never let go of the button. The boat can't move until you let go of
  the button. Please make sure you let go of the button so the boat gets to
  move. *=0= millimeters*.

Since the current record for this race is =9= millimeters, there are actually
*=4=* different ways you could win: you could hold the button for =2=, =3=, =4=,
or =5= milliseconds at the start of the race.

In the second race, you could hold the button for at least =4= milliseconds and
at most =11= milliseconds and beat the record, a total of *=8=* different ways
to win.

In the third race, you could hold the button for at least =11= milliseconds and
no more than =19= milliseconds and still beat the record, a total of *=9=* ways
you could win.

To see how much margin of error you have, determine the *number of ways you can
beat the record* in each race; in this example, if you multiply these values
together, you get *=288=* (=4= * =8= * =9=).

Determine the number of ways you could beat the record in each race. *What do
you get if you multiply these numbers together?*
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-06-1-aoc.txt][2023-12-06-1-aoc.txt]]

The solution for this problem is shorter than the task description!

As always - let's load the data. Note: we use the =delim_whitesspace= argument
instead of ~sep=' '~ to separate values by spaces of any length.

#+begin_src jupyter-python
import pandas as pd
import numpy as np

race = pd.read_table('data/2023-12-06-1-aoc.txt', delim_whitespace=True,
                     header=None, index_col=0)
race.index = ['time', 'distance']
race
#+end_src

#+RESULTS:
:RESULTS:
|          | 1   | 2    | 3    | 4    |
|----------+-----+------+------+------|
| time     | 51  | 92   | 68   | 90   |
| distance | 222 | 2031 | 1126 | 1225 |
:END:

The we use Python list comprehensions to quickly calculate all distances for the
range of the =time= value (and keep only the winning distances). Then we get the
respective lengths and compute the product.

#+begin_src jupyter-python
def get_distance(time, distance):
    return [t * (time - t) for t in range(1, time + 1)
            if (t * (time - t)) > distance]

race.loc['nwins', :] = [len(get_distance(int(r.time), int(r.distance)))
                        for c, r in race.items()]
nwins_prod = np.prod(race.loc['nwins', :].values, dtype=int)
display(race)
print(f'The product of our nwins is {nwins_prod}')
#+end_src

#+RESULTS:
:RESULTS:
|          | 1     | 2      | 3      | 4      |
|----------+-------+--------+--------+--------|
| time     | 51.0  | 92.0   | 68.0   | 90.0   |
| distance | 222.0 | 2031.0 | 1126.0 | 1225.0 |
| nwins    | 42.0  | 19.0   | 11.0   | 57.0   |
: The product of our nwins is 500346
:END:

*** Part 2

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary
#+begin_quote
As the race is about to start, you realize the piece of paper with race times
and record distances you got earlier actually just has very bad [[https:en.wikipedia.org/wiki/Kerning][kerning]]. There's
really *only one race* - ignore the spaces between the numbers on each line.

So, the example from before:
#+end_quote

#+begin_example
Time:      7  15   30
Distance:  9  40  200
#+end_example

#+begin_quote
...now instead means this:
#+end_quote

#+begin_example
Time:      71530
Distance:  940200
#+end_example

#+begin_quote
Now, you have to figure out how many ways there are to win this single race. In
this example, the race lasts for *=71530= milliseconds* and the record distance
you need to beat is *=940200= millimeters*. You could hold the button anywhere
from =14= to =71516= milliseconds and beat the record, a total of *=71503=*
ways!

*How many ways can you beat the record in this one much longer race?*
#+end_quote
#+end_details

For this riddle we can take the same approach as for /Part 1/. The cell took 18s
to evaluate on a consumer laptop from 2015 - no fancy workarounds needed :)

#+begin_src jupyter-python
racetime = int(''.join(str(r) for r in race.loc['time', :4].astype(int)))
racedist = int(''.join(str(r) for r in race.loc['distance', :4].astype(int)))
racewins = len(get_distance(racetime, racedist))

race[5] = [racetime, racedist, racewins]
race
#+end_src

#+RESULTS:
:RESULTS:
|          | 1     | 2      | 3      | 4      | 5               |
|----------+-------+--------+--------+--------+-----------------|
| time     | 51.0  | 92.0   | 68.0   | 90.0   | 51926890        |
| distance | 222.0 | 2031.0 | 1126.0 | 1225.0 | 222203111261225 |
| nwins    | 42.0  | 19.0   | 11.0   | 57.0   | 42515755        |
:END:

** DONE Advent of code 2023 - Tag 6: Warte Darauf :python:
CLOSED: [2024-01-04 Do 00:45]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day06.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 6 - siehe [[https:adventofcode.com/2023/day/6]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.
** DONE Advent of code 2023 - Day 7: Camel Cards :python:
CLOSED: [2024-01-04 Do 16:32]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day07.en.md
:END:

This year I try to record my attempt at solving the *Advent of Code 2023*
riddles. This is Day 7 - see [[https:adventofcode.com/2023/day/7]]
*** Part 1

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
In Camel Cards, you get a list of *hands*, and your goal is to order them based
on the *strength* of each hand. A hand consists of *five cards* labeled one of
=A=, =K=, =Q=, =J=, =T=, =9=, =8=, =7=, =6=, =5=, =4=, =3=, or =2=. The relative
strength of each card follows this order, where =A= is the highest and =2= is
the lowest.

Every hand is exactly one type. From strongest to weakest, they are:

- *Five of a kind*, where all five cards have the same label: =AAAAA=
- *Four of a kind*, where four cards have the same label and one card has a
  different label: =AA8AA=
- *Full house*, where three cards have the same label, and the remaining two
  cards share a different label: =23332=
- *Three of a kind*, where three cards have the same label, and the remaining
  two cards are each different from any other card in the hand: =TTT98=
- *Two pair*, where two cards share one label, two other cards share a second
  label, and the remaining card has a third label: =23432=
- *One pair*, where two cards share one label, and the other three cards have a
  different label from the pair and each other: =A23A4=
- *High card*, where all cards' labels are distinct: =23456=

Hands are primarily ordered based on type; for example, every *full house* is
stronger than any *three of a kind*.

If two hands have the same type, a second ordering rule takes effect. Start by
comparing the *first card in each hand*. If these cards are different, the hand
with the stronger first card is considered stronger. If the first card in each
hand have the *same label*, however, then move on to considering the *second card
in each hand*. If they differ, the hand with the higher second card wins;
otherwise, continue with the third card in each hand, then the fourth, then the
fifth.

So, =33332= and =2AAAA= are both *four of a kind* hands, but =33332= is stronger
because its first card is stronger. Similarly, =77888= and =77788= are both a
*full house*, but =77888= is stronger because its third card is stronger (and
both hands have the same first and second card).

To play Camel Cards, you are given a list of hands and their corresponding *bid*
(your puzzle input). For example:
#+end_quote

#+begin_example
32T3K 765
T55J5 684
KK677 28
KTJJT 220
QQQJA 483
#+end_example

#+begin_quote
This example shows five hands; each hand is followed by its *bid* amount. Each
hand wins an amount equal to its bid multiplied by its *rank*, where the weakest
hand gets rank 1, the second-weakest hand gets rank 2, and so on up to the
strongest hand. Because there are five hands in this example, the strongest hand
will have rank 5 and its bid will be multiplied by 5.

So, the first step is to put the hands in order of strength:

- =32T3K= is the only *one pair* and the other hands are all a stronger type, so
  it gets rank *1*.
- =KK677= and =KTJJT= are both *two pair*. Their first cards both have the same
  label, but the second card of =KK677= is stronger (=K= vs =T=), so =KTJJT=
  gets rank *2* and =KK677= gets rank *3*.
- =T55J5= and =QQQJA= are both *three of a kind*. =QQQJA= has a stronger first
  card, so it gets rank *5* and =T55J5= gets rank *4*.

Now, you can determine the total winnings of this set of hands by adding up the
result of multiplying each hand's bid with its rank (=765= * 1 + =220= * 2 +
=28= * 3 + =684= * 4 + =483= * 5). So the *total winnings* in this example are
*=6440=*.

Find the rank of every hand in your set. What are the total winnings?
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-07-1-aoc.txt][2023-12-07-1-aoc.txt]]

As always - let's read in the data.

#+begin_src jupyter-python
import pandas as pd

camel = pd.read_table('data/2023-12-07-1-aoc.txt', delim_whitespace=True,
                      header=None, names=['cards', 'bid'],
                      dtype={'cards': 'string', 'bid': 'Int64'})
camel
#+end_src

#+RESULTS:
:RESULTS:
|     | cards | bid |
|-----+-------+-----|
| 0   | A833A | 309 |
| 1   | Q33J3 | 205 |
| 2   | 55KK5 | 590 |
| 3   | K4457 | 924 |
| 4   | Q3QT3 | 11  |
| ... | ...   | ... |
| 995 | KQJ53 | 367 |
| 996 | 57866 | 537 |
| 997 | Q94A9 | 210 |
| 998 | J448A | 903 |
| 999 | 6J66J | 114 |

1000 rows × 2 columns
:END:

For sorting, we need to compute a =type= column. The 7 types can be deduced
based on how many different cards are there (through =set()=) and the number of
cards.

Also, for the next step we prepare one column per card string in the =cards=.

#+begin_src jupyter-python
def get_type(cards):
    cardset = set(cards)
    cardlen = len(cardset)
    cardlist = list(cards)
    cardnum = [cardlist.count(i) for i in cardset]
    if cardlen == 1:
        ctype = 1
    elif cardlen in (4, 5):
        ctype = cardlen + 2
    elif cardlen == 2:
        ctype = 2 if set(cardnum) == {1, 4} else 3
    else:
        ctype = 4 if 3 in cardnum else 5
    return ctype

camel['type'] = camel.loc[:, 'cards'].apply(lambda x: get_type(x))
for i in range(5):
    camel[f'c{i}'] = camel.loc[:, 'cards'].apply(lambda x: list(x)[i])
camel
#+end_src

#+RESULTS:
:RESULTS:
|     | cards | bid | type | c0  | c1  | c2  | c3  | c4  |
|-----+-------+-----+------+-----+-----+-----+-----+-----|
| 0   | A833A | 309 | 5    | A   | 8   | 3   | 3   | A   |
| 1   | Q33J3 | 205 | 4    | Q   | 3   | 3   | J   | 3   |
| 2   | 55KK5 | 590 | 3    | 5   | 5   | K   | K   | 5   |
| 3   | K4457 | 924 | 6    | K   | 4   | 4   | 5   | 7   |
| 4   | Q3QT3 | 11  | 5    | Q   | 3   | Q   | T   | 3   |
| ... | ...   | ... | ...  | ... | ... | ... | ... | ... |
| 995 | KQJ53 | 367 | 7    | K   | Q   | J   | 5   | 3   |
| 996 | 57866 | 537 | 6    | 5   | 7   | 8   | 6   | 6   |
| 997 | Q94A9 | 210 | 6    | Q   | 9   | 4   | A   | 9   |
| 998 | J448A | 903 | 6    | J   | 4   | 4   | 8   | A   |
| 999 | 6J66J | 114 | 3    | 6   | J   | 6   | 6   | J   |

1000 rows × 8 columns
:END:

For sorting, =pandas= contributes the =sort_values= method, which supports
sorting by multiple columns (here, we first sort according to =type=, then =c0=,
=c1=, ...). For easier sorting by numerical values, we convert the values using
the =card_dict= dictionary, which implements the given sorting order.

#+begin_src jupyter-python
card_dict = {c: i for i, c in enumerate([7, 6, 5, 4, 3, 2, 1, '2', '3',
                                         '4', '5', '6', '7', '8', '9',
                                         'T', 'J', 'Q', 'K', 'A'])}

camel = camel.sort_values(by=['type', 'c0', 'c1', 'c2', 'c3', 'c4'],
                          ignore_index=True,
                          key=lambda x: x.map(card_dict))
camel.index += 1
camel
#+end_src

#+RESULTS:
:RESULTS:
|      | cards | bid | type | c0  | c1  | c2  | c3  | c4  |
|------+-------+-----+------+-----+-----+-----+-----+-----|
| 1    | 237AQ | 157 | 7    | 2   | 3   | 7   | A   | Q   |
| 2    | 23K47 | 759 | 7    | 2   | 3   | K   | 4   | 7   |
| 3    | 249K8 | 612 | 7    | 2   | 4   | 9   | K   | 8   |
| 4    | 264A7 | 341 | 7    | 2   | 6   | 4   | A   | 7   |
| 5    | 26578 | 10  | 7    | 2   | 6   | 5   | 7   | 8   |
| ...  | ...   | ... | ...  | ... | ... | ... | ... | ... |
| 996  | AA5AA | 565 | 2    | A   | A   | 5   | A   | A   |
| 997  | AAATA | 704 | 2    | A   | A   | A   | T   | A   |
| 998  | AAAA3 | 145 | 2    | A   | A   | A   | A   | 3   |
| 999  | AAAAJ | 594 | 2    | A   | A   | A   | A   | J   |
| 1000 | JJJJJ | 219 | 1    | J   | J   | J   | J   | J   |

1000 rows × 8 columns
:END:

Lastly, we multiply the bid with the index and sum the result.

#+begin_src jupyter-python
camel.loc[:, 'bid'].mul(camel.index).sum()
#+end_src

#+RESULTS:
: 246912307

*** Part 2

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary
#+begin_quote
To make things a little more interesting, the Elf introduces one additional
rule. Now, =J= cards are jokers - wildcards that can act like whatever card
would make the hand the strongest type possible.

To balance this, *=J= cards are now the weakest* individual cards, weaker even
than =2=. The other cards stay in the same order: =A=, =K=, =Q=, =T=, =9=, =8=,
=7=, =6=, =5=, =4=, =3=, =2=, =J=.

=J= cards can pretend to be whatever card is best for the purpose of determining
hand type; for example, =QJJQ2= is now considered *four of a kind*. However, for
the purpose of breaking ties between two hands of the same type, =J= is always
treated as =J=, not the card it's pretending to be: =JKKK2= is weaker than
=QQQQ2= because =J= is weaker than =Q=.

Now, the above example goes very differently:
#+end_quote

#+begin_example
32T3K 765
T55J5 684
KK677 28
KTJJT 220
QQQJA 483
#+end_example

#+begin_quote
- =32T3K= is still the only *one pair*; it doesn't contain any jokers, so its
  strength doesn't increase.
- =KK677= is now the only *two pair*, making it the second-weakest hand.
- =T55J5=, =KTJJT=, and =QQQJA= are now all *four of a kind*! =T55J5= gets rank
  3, =QQQJA= gets rank 4, and =KTJJT= gets rank 5.

With the new joker rule, the total winnings in this example are *=5905=*.

Using the new joker rule, find the rank of every hand in your set. *What are the
new total winnings?*
#+end_quote
#+end_details

What changes? We have to update our =get_type()= function and our =card_dict=
dictionary, otherwise the method stays the same!

Let's first write =get_type_joker()=: if no joker is in the cards, we can just
refer to =get_type()=. If we have 1, 2 or 5 different card faces, the answer is
trivial. We only have to use the number of jokers and the maximum number of
other faces if we have 3 or 4 different faces.

Note: if a =J= is present, there can never be *high card* (~type = 7~), because
we always can get *one pair*. Also we can never get *two pair* (~type = 5~),
because we can always construct *three of a kind* or *full house*.

#+begin_src jupyter-python
def get_type_joker(cards):
    cardset = set(cards)
    cardlen = len(cardset)
    cardlist = list(cards)
    cardnum = [cardlist.count(i) for i in cardset]
    if not 'J' in cardset:
        ctype = get_type(cards)
    else:
        idxj = list(cardset).index('J')
        numj = cardnum[idxj]
        cardnum.pop(idxj)
        if cardlen in [1, 2]:
            ctype = 1
        elif cardlen == 5:
            ctype = 6
        else:
            if (numj in [1, 2]) and (cardlen == 4):
                ctype = 4
            else:
                ctype = 6 - max(cardnum) - numj
    return ctype

camel['type'] = camel.loc[:, 'cards'].apply(lambda x: get_type_joker(x))

camel
#+end_src

#+RESULTS:
:RESULTS:
|      | cards | bid | type | c0  | c1  | c2  | c3  | c4  |
|------+-------+-----+------+-----+-----+-----+-----+-----|
| 1    | 237AQ | 157 | 7    | 2   | 3   | 7   | A   | Q   |
| 2    | 23K47 | 759 | 7    | 2   | 3   | K   | 4   | 7   |
| 3    | 249K8 | 612 | 7    | 2   | 4   | 9   | K   | 8   |
| 4    | 264A7 | 341 | 7    | 2   | 6   | 4   | A   | 7   |
| 5    | 26578 | 10  | 7    | 2   | 6   | 5   | 7   | 8   |
| ...  | ...   | ... | ...  | ... | ... | ... | ... | ... |
| 996  | AA5AA | 565 | 2    | A   | A   | 5   | A   | A   |
| 997  | AAATA | 704 | 2    | A   | A   | A   | T   | A   |
| 998  | AAAA3 | 145 | 2    | A   | A   | A   | A   | 3   |
| 999  | AAAAJ | 594 | 1    | A   | A   | A   | A   | J   |
| 1000 | JJJJJ | 219 | 1    | J   | J   | J   | J   | J   |

1000 rows × 8 columns
:END:

Now, we just move =J= in our new =card_dict_joker= to where it belongs, the rest
of the solution is the same.

#+begin_src jupyter-python
card_dict_joker = {c: i for i, c in enumerate(
    [7, 6, 5, 4, 3, 2, 1, 'J', '2', '3', '4', '5', '6', '7', '8', '9',
     'T', 'Q', 'K', 'A'])}

camel = camel.sort_values(by=['type', 'c0', 'c1', 'c2', 'c3', 'c4'],
                          ignore_index=True,
                          key=lambda x: x.map(card_dict_joker))
camel.index += 1
display(camel)
print('Our new solution: ', camel.loc[:, 'bid'].mul(camel.index).sum())
#+end_src

#+RESULTS:
:RESULTS:
|      | cards | bid | type | c0  | c1  | c2  | c3  | c4  |
|------+-------+-----+------+-----+-----+-----+-----+-----|
| 1    | 237AQ | 157 | 7    | 2   | 3   | 7   | A   | Q   |
| 2    | 23K47 | 759 | 7    | 2   | 3   | K   | 4   | 7   |
| 3    | 249K8 | 612 | 7    | 2   | 4   | 9   | K   | 8   |
| 4    | 264A7 | 341 | 7    | 2   | 6   | 4   | A   | 7   |
| 5    | 26578 | 10  | 7    | 2   | 6   | 5   | 7   | 8   |
| ...  | ...   | ... | ...  | ... | ... | ... | ... | ... |
| 996  | TJTTJ | 609 | 1    | T   | J   | T   | T   | J   |
| 997  | QQJQJ | 131 | 1    | Q   | Q   | J   | Q   | J   |
| 998  | QQQJQ | 831 | 1    | Q   | Q   | Q   | J   | Q   |
| 999  | KKKJK | 183 | 1    | K   | K   | K   | J   | K   |
| 1000 | AAAAJ | 594 | 1    | A   | A   | A   | A   | J   |

1000 rows × 8 columns
: Our new solution:  246894760
:END:

** DONE Advent of code 2023 - Tag 7: Kamelkarten :python:
CLOSED: [2024-01-04 Do 16:33]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2023-day07.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code
2023*. Dies ist Tag 7 - siehe [[https:adventofcode.com/2023/day/7]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.

** DONE Advent of code 2024 - Day 1: Historian Hysteria :R:
CLOSED: [2024-12-07 Sa 00:22]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2024-day01.en.md
:END:

I try to solve this year's *Advent of Code 2024* riddles in R. This is Day 1 - see [[https:adventofcode.com/2024/day/1]]
*** Part 1: Locations

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
Throughout the Chief's office, the historically significant locations are listed
not by name but by a unique number called the *location ID*. To make sure they
don't miss anything, The Historians split into two groups, each searching the
office and trying to create their own complete list of location IDs.

There's just one problem: by holding the two lists up *side by side* (your
puzzle input), it quickly becomes clear that the lists aren't very similar.
Maybe you can help The Historians reconcile their lists?

For example:
#+end_quote

#+begin_example
3   4
4   3
2   5
1   3
3   9
3   3
#+end_example

#+begin_quote
Maybe the lists are only off by a small amount! To find out, pair up the numbers
and measure how far apart they are. Pair up the *smallest number in the left
list* with the *smallest number in the right list*, then the *second-smallest
left number* with the *second-smallest right number*, and so on.

Within each pair, figure out *how far apart* the two numbers are; you'll need to
*add up all of those distances*. For example, if you pair up a =3= from the left
list with a =7= from the right list, the distance apart is =4=; if you pair up a
=9= with a =3=, the distance apart is =6=.

In the example list above, the pairs and distances would be as follows:

- The smallest number in the left list is =1=, and the smallest number in the
  right list is =3=. The distance between them is *=2=*.
- The second-smallest number in the left list is =2=, and the second-smallest
  number in the right list is another =3=. The distance between them is *=1=*.
- The third-smallest number in both lists is =3=, so the distance between them
  is *=0=*.
- The next numbers to pair up are =3= and =4=, a distance of *=1=*.
- The fifth-smallest numbers in each list are =3= and =5=, a distance of *=2=*.
- Finally, the largest number in the left list is =4=, while the largest number
  in the right list is =9=; these are a distance *=5=* apart.

To find the *total distance* between the left list and the right list, add up
the distances between all of the pairs you found. In the example above, this is
=2 + 1 + 0 + 1 + 2 + 5=, a total distance of *=11=*!

Your actual left and right lists contain many location IDs. *What is the total distance between your lists?*
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2023-12-03-1-aoc.txt][2024-12-01-1-aoc.txt]]

#+begin_src jupyter-R :exports none
setwd("~/Programs/aseltmann.github.io-org-src/data")
#+end_src

#+RESULTS:

First, we read the data - the =fread= command from the =data.table= package is
more versatile than =read.delim= from =base= and directly reads the data as a
=data.table=, which has [[https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html][some benefits]].

#+begin_src jupyter-R
data <- data.table::fread("2024-12-01-1-aoc.txt", header = FALSE)
head(data)
#+end_src

#+RESULTS:
:RESULTS:
| V1    | V2    |
|-------+-------|
| <int> | <int> |
| 41226 | 69190 |
| 89318 | 10100 |
| 59419 | 23880 |
| 63157 | 20193 |
| 81510 | 22869 |
| 83942 | 63304 |
#+caption: A data.table: 6 × 2
:END:

Now, the idea is to get the ordered versions of =V1= and =V2=.

#+begin_src jupyter-R
v1 <- data[order(V1)]$V1
v2 <- data[order(V2)]$V2
head(v1)
#+end_src

#+RESULTS:
:RESULTS:
1. 10188
2. 10314
3. 10319
4. 10348
5. 10408
6. 10668
:END:

Coming from Python, this syntax looks a bit odd. The documentation of
=data.table::setorder= helps:

#+begin_example
setorder (and setorderv) reorders the rows of a data.table based on the columns (and column
order) provided. It reorders the table by reference and is therefore very memory efficient.

Note that queries like x[order(.)] are optimised internally to use data.table's fast order.
#+end_example

So, =data[order(V1)]= is actually short for =data.table::setorder(data, V1)=.
Then, we extract the vector by name using the =$= operator, which allows to
extract elements by name.

#+begin_src jupyter-R
head(data.table::setorder(data, V1)$V1)
#+end_src

#+RESULTS:
:RESULTS:
1. 10188
2. 10314
3. 10319
4. 10348
5. 10408
6. 10668
:END:

The actual computation is just the sum of the absolute difference:

#+begin_src jupyter-R
sum(abs(v1 - v2))
#+end_src

#+RESULTS:
:RESULTS:
3574690
:END:

*** Part 2: Similarities

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
This time, you'll need to figure out exactly how often each number from the left
list appears in the right list. Calculate a total *similarity score* by adding
up each number in the left list after multiplying it by the number of times that
number appears in the right list.

Here are the same example lists again:
#+end_quote

#+begin_example
3   4
4   3
2   5
1   3
3   9
3   3
#+end_example

#+begin_quote
For these example lists, here is the process of finding the similarity score:

- The first number in the left list is =3=. It appears in the right list three
  times, so the similarity score increases by ~3 * 3 = 9~.
- The second number in the left list is =4=. It appears in the right list once,
  so the similarity score increases by ~4 * 1 = 4~.
- The third number in the left list is =2=. It does not appear in the right
  list, so the similarity score does not increase (~2 * 0 = 0~).
- The fourth number, =1=, also does not appear in the right list.
- The fifth number, =3=, appears in the right list three times; the similarity
  score increases by *=9=*.
- The last number, =3=, appears in the right list three times; the similarity
  score again increases by *=9=*.

So, for these example lists, the similarity score at the end of this process is
*=31=* (=9 + 4 + 0 + 0 + 9 + 9=).

Once again consider your left and right lists. *What is their similarity score?*
#+end_quote
#+end_details

My idea here is simple - we first count the occurrences of =V2= to be able to
check =V1= against them. Here, applying the =table= command works like
=pandas.value_counts()= and achieves this. We convert the output to a
=data.frame= and assign the =V1= values as row names. Note: =table= converts the
values which are counted to string, e.g. ="10019"= instead of =10019=.

#+begin_src jupyter-R
tab <- table(v2)
v2series <- data.frame(c(tab), row.names = names(tab))
head(v2series)
v2series["10019", ]
#+end_src

#+RESULTS:
:RESULTS:
|       | c.tab. |
|-------+--------|
|       | <int>  |
| 10019 | 1      |
| 10100 | 1      |
| 10206 | 1      |
| 10428 | 1      |
| 10645 | 1      |
| 10972 | 1      |
#+caption: A data.frame: 6 × 1
1
:END:

Now, we loop through =V1= and try to access the frequency in =V2= (by converting
to string first, via =as.character=). If nothing is found in =V2=, an =NA= value
is returned. For everything that is not NA, we compute the similarity score,
append it to a list, and sum in the end. Note: a list in R can not directly be
summed (I don't know why that is) - so we have to =unlist= first.

#+begin_src jupyter-R
sim <- list()
for (num in v1) {
    myfreq <- v2series[as.character(num), ]
    if (!is.na(myfreq)) {
        score <- myfreq * num
        sim <- append(sim, score)
    }

}
sum(unlist(sim))
#+end_src

#+RESULTS:
:RESULTS:
22565391
:END:

** DONE Advent of code 2024 - Tag 1: Hysterie der Historiker:innen :R:
CLOSED: [2024-12-07 Sa 00:23]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2024-day01.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code 2024*
in der auf Statistik fokussierten Programmiersprache *R*. Dies ist Tag 1 - siehe
[[https:adventofcode.com/2024/day/1]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.

** DONE Advent of code 2024 - Day 2: Red-Nosed Reports :R:
CLOSED: [2024-12-10 Di 01:43]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2024-day02.en.md
:END:

I try to solve this year's *Advent of Code 2024* riddles in R. This is Day 2 - see [[https:adventofcode.com/2024/day/2]]
*** Part 1: Safe reports

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
The unusual data (your puzzle input) consists of many *reports*,
one report per line. Each report is a list of numbers called *levels* that are
separated by spaces. For example:
#+end_quote

#+begin_example
7 6 4 2 1
1 2 7 8 9
9 7 6 2 1
1 3 2 4 5
8 6 4 4 1
1 3 6 7 9
#+end_example

#+begin_quote
This example data contains six reports each containing five levels.

The engineers are trying to figure out which reports are *safe*. The Red-Nosed
reactor safety systems can only tolerate levels that are either gradually
increasing or gradually decreasing. So, a report only counts as safe if both of
the following are true:

- The levels are either *all increasing* or *all decreasing*.
- Any two adjacent levels differ by *at least one* and *at most three*.

In the example above, the reports can be found safe or unsafe by checking those
rules:

- =7 6 4 2 1=: *Safe* because the levels are all decreasing by 1 or 2.
- =1 2 7 8 9=: *Unsafe* because =2 7= is an increase of 5.
- =9 7 6 2 1=: *Unsafe* because =6 2= is a decrease of 4.
- =1 3 2 4 5=: *Unsafe* because =1 3= is increasing but =3 2= is decreasing.
- =8 6 4 4 1=: *Unsafe* because =4 4= is neither an increase or a decrease.
- =1 3 6 7 9=: *Safe* because the levels are all increasing by 1, 2, or 3.

So, in this example, *=2=* reports are *safe*.

Analyze the unusual data from the engineers. *How many reports are safe?*
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2024-12-02-1-aoc.txt][2024-12-02-1-aoc.txt]]

First, let's load the data and take a look:

#+begin_src jupyter-R :exports none
setwd("~/Programs/aseltmann.github.io-org-src/data")
#+end_src

#+RESULTS:

#+begin_src jupyter-R
data <- data.table::fread("2024-12-02-1-aoc.txt", header = FALSE, fill = TRUE)
head(data)
#+end_src

#+RESULTS:
:RESULTS:
| V1    | V2    | V3    | V4    | V5    | V6    | V7    | V8    |
|-------+-------+-------+-------+-------+-------+-------+-------|
| <int> | <int> | <int> | <int> | <int> | <int> | <int> | <int> |
| 74    | 76    | 78    | 79    | 76    | NA    | NA    | NA    |
| 38    | 40    | 43    | 44    | 44    | NA    | NA    | NA    |
| 1     | 2     | 4     | 6     | 8     | 9     | 13    | NA    |
| 65    | 68    | 70    | 72    | 75    | 76    | 81    | NA    |
| 89    | 91    | 92    | 95    | 93    | 94    | NA    | NA    |
| 15    | 17    | 16    | 18    | 19    | 17    | NA    | NA    |
#+caption: A data.table: 6 × 8
:END:

My core idea here was to compute the differences between each element in a row -
luckily, =R= provides an inbuilt =diff()= function that provides exactly what I
need. Then, we check if all differences are either 1, 2, 3 or -1, -2, -3. Note
that each row has a different number of elements, so we have to omit NA values
via =na.omit= when applying the check.

#+begin_src jupyter-R
isalltrue <- function(rep) {
    return(all(diff(rep) %in% c(1, 2, 3)) |
           all(diff(rep) %in% c(-1, -2, -3)))
}

isreport <- function(row) {
    return(isalltrue(na.omit(row)))
}
valid.reports <- apply(data, 1, isreport)
table(valid.reports)
#+end_src

#+RESULTS:
: valid.reports
: FALSE  TRUE
:   743   257

*** Part 2: Problem Dampener

#+begin_details
#+begin_summary
Let's read the task for part 2!
#+end_summary

#+begin_quote
The engineers are surprised by the low number of safe reports until they realize
they forgot to tell you about the Problem Dampener.

The Problem Dampener is a reactor-mounted module that lets the reactor safety
systems *tolerate a single bad level* in what would otherwise be a safe report.
It's like the bad level never happened!

Now, the same rules apply as before, except if removing a single level from an
unsafe report would make it safe, the report instead counts as safe.

More of the above example's reports are now safe:

- -=7 6 4 2 1=: *Safe* without removing any level.
- -=1 2 7 8 9=: *Unsafe* regardless of which level is removed.
- -=9 7 6 2 1=: *Unsafe* regardless of which level is removed.
- -=1 3 2 4 5=: *Safe* by removing the second level, =3=.
- -=8 6 4 4 1=: *Safe* by removing the third level, =4=.
- -=1 3 6 7 9=: *Safe* without removing any level.

Thanks to the Problem Dampener, *=4=* reports are actually *safe*!

Update your analysis by handling situations where the Problem Dampener can
remove a single level from unsafe reports. *How many reports are now safe?*
#+end_quote
#+end_details

So, this task is a good example on how easy it is to get lost in a overly
complicated approach. My first approach was basically to somehow check if the
general trend was descending or ascending and based on that to remove opposite
differences. This was too complicated and in the end I found 4 less safe reports
than were needed... (Also note the beautiful print debuggin...)

#+begin_details
#+begin_src jupyter-R

isalltrue <- function(reptrue1, reptrue2) {
    return((all(reptrue1) == TRUE) | (all(reptrue2) == TRUE))
}

iscorrtrue <- function(rep, reptrue) {
    rep <- rep[-which.min(reptrue)]
    repdiff <- diff(rep)
    reptrue1 <- !(repdiff < 1 | repdiff > 3)
    reptrue2 <- !(repdiff < -3 | repdiff > -1)
    out <- isalltrue(reptrue1, reptrue2)
    print(rep)
    print(out)
    return(out)
}

isreport2 <- function(row) {
    print("")
    rep <- na.omit(as.numeric(row))
    print(c(rep))
    repdiff <- c(1, diff(rep))
    reptrue1 <- !(repdiff < 1 | repdiff > 3)
    repdiff <- c(-1, diff(rep))
    reptrue2 <- !(repdiff < -3 | repdiff > -1)
    if (isalltrue(reptrue1, reptrue2) == TRUE) {
        out <- isalltrue(reptrue1, reptrue2)
        print("----- 1 -----")
        print(out)
    } else if (sum(diff(rep) > 0) > sum(diff(rep) < 0)) {
        print("----- 2 -----")
        out <- iscorrtrue(rep, reptrue1)
    } else if (sum(diff(rep) < 0) > sum(diff(rep) > 0)) {
        print("----- 3 -----")
        out <- iscorrtrue(rep, reptrue2)
    } else {
        out <- FALSE
    }
    if (out == FALSE) {
        print("----- 4 -----")
        rep <- na.omit(as.numeric(row))[-1]
        repdiff <- diff(rep)
        reptrue1 <- !(repdiff < 1 | repdiff > 3)
        reptrue2 <- !(repdiff < -3 | repdiff > -1)
        out <- isalltrue(reptrue1, reptrue2)
        print(c(rep))
        print(out)
    }
    return(out)
}
#+end_src


#+end_details

My actual working approach was in the end *brute force*. I just threw out each
element in a row and checked if the report became positive - much simpler and effective!

#+begin_src jupyter-R
isreport2 <- function(row) {
    rep <- na.omit(row)
    out <- isalltrue(rep)
    if (out == FALSE) {
        for (i in seq_along(rep)) {
            # rep <- rep[-i] does not update the variable
            # with rep.i, a new variable is assigned (rep.1, rep.2, ...)
            rep.i <- rep[-i]
            out <- isalltrue(rep.i)
            if (out == TRUE) {
                break
            }
        }
    }
    return(out)
}
sum(apply(data, 1, isreport2))
#+end_src

#+RESULTS:
:RESULTS:
328
:END:


** DONE Advent of code 2024 - Tag 2: Rotnasige Berichte :R:
CLOSED: [2024-12-10 Di 00:23]
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2024-day02.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code 2024*
in der auf Statistik fokussierten Programmiersprache *R*. Dies ist Tag 2 - siehe
[[https:adventofcode.com/2024/day/2]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.


** TODO Advent of code 2024 - Day 3: Mull It Over :R:
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2024-day03.en.md
:END:

I try to solve this year's *Advent of Code 2024* riddles in R. This is Day 3 -
see [[https:adventofcode.com/2024/day/3]]
*** Part 1: mul()

#+begin_details
#+begin_summary
Lets first read the task:
#+end_summary

#+begin_quote
The computer appears to be trying to run a program, but its memory (your puzzle
input) is *corrupted*. All of the instructions have been jumbled up!

It seems like the goal of the program is just to *multiply some numbers*. It does
that with instructions like =mul(X,Y)=, where =X= and =Y= are each 1-3 digit numbers.
For instance, =mul(44,46)= multiplies =44= by =46= to get a result of =2024=. Similarly,
=mul(123,4)= would multiply =123= by =4=.

However, because the program's memory has been corrupted, there are also many
invalid characters that should be *ignored*, even if they look like part of a =mul=
instruction. Sequences like =mul(4*=, =mul(6,9!=, =?(12,34)=, or =mul ( 2 , 4 )= do
*nothing*.

For example, consider the following section of corrupted memory:

=xmul(2,4)%&mul[3,7]!@^do_not_mul(5,5)+mul(32,64]then(mul(11,8)mul(8,5)) Only the
four highlighted sections are real mul instructions. Adding up the result of
each instruction produces 161 (2*4 + 5*5 + 11*8 + 8*5).

Scan the corrupted memory for uncorrupted mul instructions. What do you get if
you add up all of the results of the multiplications?
#+end_quote
#+end_details

My input file: [[https://github.com/aseltmann/aseltmann.github.io-org-src/blob/main/data/2024-12-03-1-aoc.txt][2024-12-03-1-aoc.txt]]

First, let's load the data and take a look:

#+begin_src jupyter-R :exports none
setwd("~/Programs/hugo-book/data")
#+end_src

#+RESULTS:

#+begin_src jupyter-R
library(tidyverse)
#+end_src

#+RESULTS:
#+begin_example
── Attaching core tidyverse packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2
── Conflicts ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
#+end_example


#+begin_src jupyter-R
connection <- file("2024-12-03-1-aoc.txt", open = "r")
lines <- readLines(connection)
print(lines[1])
#+end_src

#+RESULTS:
: [1] "?% mul(948,148)why() %how(670,744)mul(590,32);where())#}from()>how()mul(611,372)}{~^?>from()^mul(835,665)who()]#^don't()select()select())mul(724,851)[>&mul(188,482)$mul(781,111)[who()<why(),!]mul(678,13)why()$#%who()mul(620,771)<!^}@^+what()mul(281,719)(]'what()where()>&from():!mul(147,678)how(){mul(938,510)where()!$?*['mul(103,563)where())mul(4,125)$*>>^mul(126,929)]& %~mul(161,418)who()>>do()]-''?mul(416,366)~?/where()]who()mul(459,47))>what(){@[(mul(219,400)+do()when()from():who()when()]&{{%mul(804,830)-select()what()*what()%}mul(861,992)who()!',mul(159,874)#<)''<mul(460,777)?mul(909,244)how()+what()]<do()?}mul(749,87)from()(who();why()mul(430,124)/$>how()@$%mul(214,139)&how()>mul(112,835)select()*from()@why()?[{mul(209,568)/; ~)mul(630,749):mul(841,589)/;who()>[mul(778,567)+when() how()<#mul(544,851)what(){+mul(327,103)from()what()/[~-mul(995,415)/when()-mul(880,153)}:}mul(368,920)'how()mul(864,419)from()what()@mul(208,291)who()<?}?what()',[{mul(575,454)*&(<{how()[mul(557,489){{why(){how()@who()~mul(423,703)mul(910,916)+what()^/<-*from()'mul(746,826),-*)/+>}^from()mul(154,571)++:>,mul(601,458)why()<;how()~from(172,16)mul(333,315)?[mul(513,260) {*mul(117,759)%]mul(77,644){($%>]&~mul(238,306)~select()from();-'who()'mul(460,352); ?select()>[[(from() mul(337,294)why()how()</$<where()don't()(?]{why()%}from()mul(367,653)~mul(910,873)^why()>mul(499,785)>what()[*:#where()*what()mul(765,210)*$[]mul(461,957)##)+}when()-@:mul(198,90)what()what()how()') )mul(258,966)]+(when()mul(535,417)where()!don't()@mul(939,319)?mul(751,538))! mul(758,675)~how()[how(),@>[where()when(29,965)mul(358,39){^what();/(where()how()mul(271,786)why():mul(792,761)do()$]%mul(740,232)>who(949,378)what()[(where()who(){who()#mul(595,343)%+mul(194,296)'mul(161,747): '{where(12,567),@mul(234,39)!+do()/who()[where()&'what()when()how())mul(138,925)),#;where()>{mul(738,864){mul(605,662)*when()%when()+( /~&mul(633,935)when()];mul(263/}*<!where(),- ~when()mul(512,798)]}where())when()who()mul(933,447)where()}mul(33,935*mul(15,975)mul(574,550)+#^;'$from(280,157)$^what()mul(919,849)@mul(18,160))$&^]how()what() when()where()mul(88,657):/from())+:/when()@]mul(71,74)from()'*:@{>mul(127,821)^how()$$select()select()@^{:mul(867,979)&%/>{%^how()what(499,657)+do()%what()(~;-:*mul(438,941)<]?]mul(208,834when()&^;]from()when(613,710)^}+$mul(809,573)mul^)*:from(379,983)mul(47,786)}when()-what()how(450,632)> where()how()mul(810,597 ;;{%(select()select()&,mul(356,249)from()/!{#&^mul(23,248)(!who()]-+,mul(873,987)]{what()<  )-{^mul(591,317)/mul(382,188)mul(476,338)*why()$]mul(865,625)who()})?select():*@[)don't()/ ,mul(737,418)select(318,357);+ what()<mul(41,445)mul(236,630)$}from()]$^$,(do()-select()mul(369,197)from()]#};^mul(561,752)+&#+}?}:mul(18,235)<'& ,(*mul(645,811)why()select()who()[>where()don't()%#>!>/@what()[mul(490,823)&^( ,'@ [do()@mul(855,491)*^why()[,mul(348,679)how()$who() '&how(16,459)/!;mul(43,422)#^from()![}select()mul(976,749)-}select()-where()select()mul(223,589)%[why()mul(868,881)mul(178,790)$,{who()from()#,mul(318,399):where()?[mul(182,864)where() mul(156,690) -]mul(857,353)#'%,},>?+@mul(914,528)where()$mul(785,748)<$who()[mul(453,859)%'@ mul(84,729)/{do()(?$<}mul(820,286)?:*?}#when()(%mul(245,958when()?from(),+mul(128,335)mul(463,102);:]@-~-%mul(914,398)"


#+begin_src jupyter-R
mullist <- stringr::str_extract_all(lines, "mul\\(\\d*,\\d*\\)")
mullist <- unlist(mullist, recursive = FALSE)
head(mullist)
#+end_src

#+RESULTS:
:RESULTS:
1. 'mul(948,148)'
2. 'mul(590,32)'
3. 'mul(611,372)'
4. 'mul(835,665)'
5. 'mul(724,851)'
6. 'mul(188,482)'
:END:


#+begin_src jupyter-R
df <- mullist |>
  data.frame() |>
  magrittr::set_colnames(c("muls")) |>
  tidyr::separate_wider_regex(
           cols = "muls",
           patterns = c(
             "mul\\(",
             mul1 = "\\d*",
             ",",
             mul2 = "\\d*"
           ),
           too_few = "align_start"
         ) |>
  mutate(
    mul1 = as.integer(mul1),
    mul2 = as.integer(mul2),
    result = mul1 * mul2
  )
head(df)
#+end_src

#+RESULTS:
:RESULTS:
| mul1  | mul2  | result |
|-------+-------+--------|
| <int> | <int> | <int>  |
| 948   | 148   | 140304 |
| 590   | 32    | 18880  |
| 611   | 372   | 227292 |
| 835   | 665   | 555275 |
| 724   | 851   | 616124 |
| 188   | 482   | 90616  |
#+caption: A tibble: 6 × 3
:END:

#+begin_src jupyter-R
sum(df$result)
#+end_src

#+RESULTS:
:RESULTS:
187833789
:END:

*** Part 2: do() and don't()

#+begin_details
#+begin_summary
Let's read the task for part 2!
#+end_summary

#+begin_quote
There are two new instructions you'll need to handle:

- The =do()= instruction *enables* future =mul= instructions.
- The =don't()= instruction *disables* future =mul= instructions.

Only the *most recent* =do()= or =don't()= instruction applies. At the beginning
of the program, mul instructions are *enabled*.

For example:

=xmul(2,4)&mul[3,7]!^don't()_mul(5,5)+mul(32,64](mul(11,8)undo()?mul(8,5))=

This corrupted memory is similar to the example from before, but this time the
=mul(5,5)= and =mul(11,8)= instructions are *disabled* because there is a =don't()=
instruction before them. The other =mul= instructions function normally, including
the one at the end that gets re-*enabled* by a =do()= instruction.

This time, the sum of the results is *=48=* (=2*4 + 8*5=).

Handle the new instructions; *what do you get if you add up all of the results of
just the enabled multiplications?*
#+end_quote
#+end_details

https://stackoverflow.com/questions/36056219/regex-match-first-occurrence-before-keyword

#+begin_src jupyter-R
lines[[4]]
#+end_src

#+RESULTS:
:RESULTS:
';@mul(257,25)[!mul(646,635)>?who()who()from()mul(25,275(select()+why()%mul(102,254)%}/where()$mul(608,18)when()*#mul(343,951)
mul(337,866)*^?#@why(805,831)-mulwhen()from()mul(854,5)when()@$why()mul(896,11)^mul(451,271)\'how()?who()?)<%[}don\'t()who()/[{]-?from()when()?mul(198,238)])mul(750,760)+/-!what()~?#mul(880,271)%?select();where()(<^select()mul(373@from()where(),mul(700,15),mul(406,120)mul(551,206)mul(636,315);+{mul(261,201)mul,:-/&mul(267,217)/,\'mul(132,410)@@;;who()when()]do()why()mul(4,121)#from()/mul(242what()how(277,558)<how()from()+:who()from()what()when()mul(27,714)who()why()what()mul(676,758)+^@*\'}mul(274,109)-}]),select()*when()]why()mul(60,516)when()when(708,630)%%where():mul(34,59)from()#]how()+who()%who()*don\'t()select()&~(;where()/mul(548,869)&mul(439,68)]@}%)~&mul(46,712)when()+[&]where(),+mul(940,261)^who()where()mul(655,165)
>\'how()how(){mul(12,537)&[>}mul(322,676)[#,do()@,mul(248,663),when()-do()^what()]when()who()what()how())mul(864,73)how()?]*mul(653,55)when()from()from()how()@
}mul(94,590)]~what()mul(164,505)]from()when()]mul(218,565)(from()
why()[*when()}[mul(306,447)*]][>
​#mul(783,715?)+^~mul(308,994):<*~)>from()why()*mul(508,139)>from()@;+~#mul(652,903)#[/?mul(407,208]how(){when(),**@*:/mul(849,965)mul(69,198<\'#%[?mul(236,808)what()from()%from()why()^/,don\'t()select()&where()@mul(888,101)
mul(332,775)who()):select()),:-mul(119,209)%how()mulfrom()select()don\'t(){mul(838,613)why()
\'({*<!mul(372,376)mul(407,117$who()[
mul(171,741)where();mul(742,142)mul(34#^+:who()mul(157,514)>~>*mul(466,106)mul(883,754->(%%who()[!mul(587,792)\'((!?select()&}<mul(791,734){how()&;+<(mul(655,63):why(){!{)mul(320,950)->-\'#)why()#[mul(234,162),what(497,671)why()#mul(985,797)>}~;from()select()mul(117,492)&~+from()]%>*$&mul(451,669))}\'/@how()?where()why(694,295)\'mul(676,756){~;select()what()}what()^}mul(963,857);%/how()?mul(944,194);select()<&^how(){->mul(195,702))?select()why()&~%}why()#mul(90,304)@%why(673,634)*/where()-
<:do(){}!mul;who()]where()]-@?<mul(919,817),>when()how()how()>mul(875,604)select()%do()%mul(790,136)*$,mul(853,95)[how()>!%?mul(246,573)&!what()/#from()!mul(382,307),!#[-mul(32,733)$+[*mul(192,47)(@who()mul(304,303)@mul(167,528):select())!:how(){what()(}mul(933,177))#>$#,$:mul(81,603)<mul(40,227)mul(717,937)mul(853,848)mul(66,164)where())^<>what()?how()when()mul(206,607)<where()[$)}when()how()select()*mul(265,447)*/what())%+\'[
from()mul(358,747)what()+%how()#from():,what()@mul(791,401)~where()[mul(990,778)?~[!:>!\'^mul(666,852)mul(651,206)!+]}from()don\'t():*]#what()mul(359*%who()^)\'mul(190,764)who()when()}select()~(~mul(547,102)mul(406,618)%when()>)<mul(822,907)?/[/from()mul(945,506)>![#mul(890,746)#who()$\'~%]\',+mul(341,395)who()--mul(285,533)}how()@<}!mul(715}>+~
select()where()$
(mul(894,62)?]}who()&when(652,875)%:}from(24,82)mul(713,250))-^{*%mul(548,903)&]]<]why(){from()when()
mul(796,100)-(how()$%~mul(589,969) :who()
@mul(271,734)<}mul(761,8)}@[\'-
[\'$mul(178,28)who()who(282,161)@$from()mul(413,253)#when()?(mul(585,394))select():$?#?>who()?mul(245,344)who()^who()where()why()~@why()don\'t()why()how()who(450,27)who()(!mul(951,644):select()-)%?*don\'t(),
mul(189,841)]*
why()*>\'mul(758,690)what()<select()~>@>mul(728,932)how()?select()what()}mul(716,985){where()who()+who():mul(840,772)%how()>:;where()mul(139,830)$select()),mul(730,4)when(305,277);[$!,)mul(278,740)who(856,922)who()#<where()*>mul(212,541)((]mul(689,475)mul(814,611)\'}&~{~~mul(716,817)who()mul(21,315))don\'t())(why()\')$<mul(541,349)'
:END:


#+begin_src jupyter-R
for(i in 1:6) {
  varname <- paste("dolistf", i, sep="")
  assign(varname, stringr::str_extract(
                             lines[[i]], "^(?:.*?)don't\\(\\)"))
  varname <- paste("dolistl", i, sep="")
  assign(varname, stringi::stri_extract_last_regex(
                             lines[[i]],
                             "(do\\(\\)).*?(^don't\\(\\))"))

}

## dolist7 <- stringr::str_extract_all(lines, "do\\(\\)(?:.*?)don't\\(\\)")
dolist7 <- stringr::str_extract_all(lines,
                                    "^(?:.*?)don't\\(\\)")
dolist8 <- stringr::str_extract_all(lines,
                                    "(?<!(don't\\(\\)))(do\\(\\)(?:.*?)don't\\(\\))")
dolist9 <- stringr::str_extract_all(lines,
                                    "do\\(\\)(?:.(?!(don't\\(\\))))+$")
dolist7 <- unlist(dolist7, recursive = FALSE)
dolist <- c(dolistf1, dolistf2, dolistf3, dolistf4, dolistf5, dolistf6,
            dolistl1, dolistl2, dolistl3, dolistl4, dolistl5, dolistl6,
            dolist7)
dolist8
#+end_src

#+RESULTS:
:RESULTS:
1.
   1. 'do()]-\'\'?mul(416,366)~?/where()]who()mul(459,47))>what(){@[(mul(219,400)+do()when()from():who()when()]&{{%mul(804,830)-select()what()*what()%}mul(861,992)who()!\',mul(159,874)#<)\'\'<mul(460,777)?mul(909,244)how()+what()]<do()?}mul(749,87)from()(who();why()mul(430,124)/$>how()@$%mul(214,139)&how()>mul(112,835)select()*from()@why()?[{mul(209,568)/;
      ~)mul(630,749):mul(841,589)/;who()>[mul(778,567)+when()
      how()<#mul(544,851)what(){+mul(327,103)from()what()/[~-mul(995,415)/when()-mul(880,153)}:}mul(368,920)\'how()mul(864,419)from()what()@mul(208,291)who()<?}?what()\',[{mul(575,454)*&(<{how()[mul(557,489){{why(){how()@who()~mul(423,703)mul(910,916)+what()^/<-*from()\'mul(746,826),-*)/+>}^from()mul(154,571)++:>,mul(601,458)why()<;how()~from(172,16)mul(333,315)?[mul(513,260)
      {*mul(117,759)%]mul(77,644){($%>]&~mul(238,306)~select()from();-\'who()\'mul(460,352);
      ?select()>[[(from() mul(337,294)why()how()</$<where()don\'t()'
   2. 'do()$]%mul(740,232)>who(949,378)what()[(where()who(){who()#mul(595,343)%+mul(194,296)\'mul(161,747):
      \'{where(12,567),@mul(234,39)!+do()/who()[where()&\'what()when()how())mul(138,925)),#;where()>{mul(738,864){mul(605,662)*when()%when()+(
      /~&mul(633,935)when()];mul(263/}*<!where(),-
      ~when()mul(512,798)]}where())when()who()mul(933,447)where()}mul(33,935*mul(15,975)mul(574,550)+#^;\'$from(280,157)$^what()mul(919,849)@mul(18,160))$&^]how()what()
      when()where()mul(88,657):/from())+:/when()@]mul(71,74)from()\'*:@{>mul(127,821)^how()$$select()select()@^{:mul(867,979)&%/>{%^how()what(499,657)+do()%what()(~;-:*mul(438,941)<]?]mul(208,834when()&^;]from()when(613,710)^}+$mul(809,573)mul^)*:from(379,983)mul(47,786)}when()-what()how(450,632)>
      where()how()mul(810,597
      ;;{%(select()select()&,mul(356,249)from()/!{#&^mul(23,248)(!who()]-+,mul(873,987)]{what()<
      )-{^mul(591,317)/mul(382,188)mul(476,338)*why()$]mul(865,625)who()})?select():*@[)don\'t()'
   3. 'do()-select()mul(369,197)from()]#};^mul(561,752)+&#+}?}:mul(18,235)<\'&
      ,(*mul(645,811)why()select()who()[>where()don\'t()'
2. 'do()\'&)when()select()mul(945,704)mul(250,874)who()]@don\'t()'
3.
   1. 'do()<#why()<why()},,select()mul(257,221)mul(393,412)-from()&$]mul(198,284)/>;/why()mul(296,969)@mul(224,163)#<$what():,what()mul(995,485)$~)who()mul(382,831)\'&~mul(146,234)mul(228,532)mul(944,430)!!who()<;\'$(%do()%\'{mul(588,828)~$why():where()mul(753(select()/\':~$[mul(785,897)/<(#$)@mul(821,858)$what()+@/*mul(545,209)where();what()mul-why()>mul(808,588),where()];;}mul(431,815)<<;how()?@why()(^don\'t()'
   2. 'do()~\'[??from()
      ​#&}mul(443,258)){do()^mul(894,293),@from()mul(470,736)/select()where()from()how()mul(769,763)/-\'mul(436,853)from()mul(955,870);#why()how()how()mul(807,205)#do()select()<@$when()*select()>mul(899,477)who(88,557){[?-mul[how()>>@mul(113,239)&;?what(825,719)from()}@mul(717,829)when()who()%@what()when()#\':mul(644,495)]^$
      >[~don\'t()'
   3. 'do()[[$what()/>(#~mul(976,792))what()#{how()-$?mul(534,805))what()@mul(600from()\'from()mul(859,367)from()mul(852,796)?{[]/\'~mul(624,853($:;^mul(522,963)+mul(143,246)[,what()#*when()\',why()mul(435,720)mul(812,909)\'<?
      /;when()}*how()do()mul(49,504)how()when()/!mul(799,134)$mul(213,950)from(182,488)];]do()mul(325,689)(@mul(485,128)who()mul(376~when()(%-what()(mul(776,635)#:
      from(788,757)}mul(997,619)-from(919,426)where()where()how()
      mul(370,735)*what(),*%$mul(408,722)}#mul(990,90)(<where()*don\'t()'
4.
   1. 'do()why()mul(4,121)#from()/mul(242what()how(277,558)<how()from()+:who()from()what()when()mul(27,714)who()why()what()mul(676,758)+^@*\'}mul(274,109)-}]),select()*when()]why()mul(60,516)when()when(708,630)%%where():mul(34,59)from()#]how()+who()%who()*don\'t()'
   2. 'do()@,mul(248,663),when()-do()^what()]when()who()what()how())mul(864,73)how()?]*mul(653,55)when()from()from()how()@
      }mul(94,590)]~what()mul(164,505)]from()when()]mul(218,565)(from()
      why()[*when()}[mul(306,447)*]][>
      ​#mul(783,715?)+^~mul(308,994):<*~)>from()why()*mul(508,139)>from()@;+~#mul(652,903)#[/?mul(407,208]how(){when(),**@*:/mul(849,965)mul(69,198<\'#%[?mul(236,808)what()from()%from()why()^/,don\'t()'
   3. 'do(){}!mul;who()]where()]-@?<mul(919,817),>when()how()how()>mul(875,604)select()%do()%mul(790,136)*$,mul(853,95)[how()>!%?mul(246,573)&!what()/#from()!mul(382,307),!#[-mul(32,733)$+[*mul(192,47)(@who()mul(304,303)@mul(167,528):select())!:how(){what()(}mul(933,177))#>$#,$:mul(81,603)<mul(40,227)mul(717,937)mul(853,848)mul(66,164)where())^<>what()?how()when()mul(206,607)<where()[$)}when()how()select()*mul(265,447)*/what())%+\'[
      from()mul(358,747)what()+%how()#from():,what()@mul(791,401)~where()[mul(990,778)?~[!:>!\'^mul(666,852)mul(651,206)!+]}from()don\'t()'
5.
   1. 'do()who()when()how()when(474,246)mul(318,180)do()%~(mul(216,96)
      ;}]why(907,964)$+when(680,212)?mul(442,979)why()what();##select()%mul(34,342)mul(641,907)@]who()@^:^mul(648,605)how()<}]when()!mul(567,219)?where()$what()~+from(),%how()mul(549,85)$-&(mul(94,269)~how(811,581)who(596,80)-how()~mul(510,591)mul(586,482)who()?#-<[[select()*}mul(249]{%<,where()*~^mul(628,294)]+what())why()mul(312,879&,?+don\'t()'
   2. 'do()*#}},},&>mul(70/:from(184,559)>mul(679,138))<mul(454,112)[@)-?*where()mul(573,473)[(-/mul(867,232)~]/^/!\'&where()mul(391,655)[%\'mul(73,32)/{->)(~mul(929,872)\'%#)mul(563,750)>(mul(324,725)what()why()[@$mul(186,770)?mul(719,251)[mul(270,934)+>when()\'$when()mul(647,486)how()from(947,190),!(?mul(113,517)
      %[select()what()^)!mul(299,591)]:@\'
      ​*where(145,530)/mulwhen()mul(811,260)mul(80,605)
      where(296,197))])>from()mul(324,361)select(){[/\';/},mul(648,947&how(){who()/\'-%*]mul(949,359){mul(288,162)&];&:^mul(188,899)select()where()]%mul(248,30)#[&+\'why()\'\')
      don\'t()'
   3. 'do()>~mul(704,518)where()!)select()?from()where()&\'do();mul(270,449)~[*mul(774,600)how():>why()[!when()mul(338,711){]mul(962,193)*where()#![-+mul(511,924):[who()why()}mul(252,534when())when()when()()\'!why(230,750)-mul(543,358)~~
      -mul(394,506){mul(176,192)who()from()%@mul(181,776)%[ don\'t()'
6.
   1. 'do() why()~]
      who()@^mul(20,119)?[$+/$^mul(242,536)who()\'-&\'from()mul(351,640){,]~mul(152,587)@select(140,751)<+mul(387,212)[where()%when())how()&
      >mul(916,539)~]?[when()>!when()??mul(322,151)!]!]~!;mul(27,537);
      ​##;^}}mul(538,277)why()mul(205,526)mul(412,826)^@?where()\'mul(957from(193,394)from(863,680)!@how()mul(771,563)(
      who()mul(377,655)
      ]select();who()mul(360,272)-select()$what(){mul(291,618)})from()^when(),how()where()don\'t()'
   2. 'do()!mul(900,510)$ %who(615,822)mul(374,872)\'\'/
      mul(808,426)select()mul(268,752)&why(),</%!:!/don\'t()'
:END:




#+begin_src jupyter-R
mullist <- stringr::str_extract_all(dolist7, "mul\\(\\d*,\\d*\\)")
mullist <- unlist(mullist, recursive = FALSE)
length(mullist)
#+end_src

#+RESULTS:
:RESULTS:
376
:END:

#+begin_src jupyter-R
df <- mullist |>
  data.frame() |>
  magrittr::set_colnames(c("muls")) |>
  tidyr::separate_wider_regex(
           cols = "muls",
           patterns = c(
             "mul\\(",
             mul1 = "\\d*",
             ",",
             mul2 = "\\d*"
           ),
           too_few = "align_start"
         ) |>
  mutate(
    mul1 = as.integer(mul1),
    mul2 = as.integer(mul2),
    result = mul1 * mul2
  )
head(df)
#+end_src

#+RESULTS:
:RESULTS:
| mul1  | mul2  | result |
|-------+-------+--------|
| <int> | <int> | <int>  |
| 948   | 148   | 140304 |
| 590   | 32    | 18880  |
| 611   | 372   | 227292 |
| 835   | 665   | 555275 |
| 416   | 366   | 152256 |
| 459   | 47    | 21573  |
#+caption: A tibble: 6 × 3
:END:

#+begin_src jupyter-R
sum(df$result)
#+end_src

#+RESULTS:
:RESULTS:
97728793
:END:


** TODO Advent of code 2024 - Tag 3: ... :R:
:PROPERTIES:
:EXPORT_FILE_NAME: aoc2024-day02.de.md
:END:

Dieses Jahr versuche ich mich an den Herausforderungen des *Advent of Code 2024*
in der auf Statistik fokussierten Programmiersprache *R*. Dies ist Tag 2 - siehe
[[https:adventofcode.com/2024/day/2]]

Für die Lösungen siehe die englische Version dieses Blogbeitrages.

** TODO Yellow Wallpaper and a king in all things - Reads June 2024 :books:
:PROPERTIES:
:EXPORT_FILE_NAME: reads2024-01.en.md
:END:

- Charlotte Perkins Gilman: The Yellow Wallpaper
  - A classic of feminist literature with a soft horror touch - a quick read
    (only 24 pages) and definitely worth it.
- Herta Müller: Der König verneigt sich und tötet (essay collection)
  - Jede Sprache hat andere Augen
  - Der König verneigt sich und tötet
** TODO The Yellow Wallpaper und der König in den Dingen - Leseliste Juni 2024
:PROPERTIES:
:EXPORT_FILE_NAME: reads2024-01.de.md
:END:
- ...

** TODO Connection on Mount Misery vs Corona
:PROPERTIES:
:EXPORT_FILE_NAME: mount-misery-corona.en.md
:END:

Eine Grundüberlegung bei Noah Sham's Mount Misery: It is not self that heals,
but connection.

Corona: Connection (soziale Nähe) tötet.

** TODO Verbindung in Mount Misery vs Corona

:PROPERTIES:
:EXPORT_FILE_NAME: mount-misery-corona.de.md
:END:

Siehe Englische Version.

** TODO Thoughts on Thea Dorn about consolation in pandemic times

:PROPERTIES:
:EXPORT_FILE_NAME: thea-dorn-trost.en.md
:END:

See German version.

** TODO Gedanken zu Thea Dorn über Trost und Religiösität in Zeiten der Pandemie

:PROPERTIES:
:EXPORT_FILE_NAME: thea-dorn-trost.de.md
:END:

In einer kürzlich erschienenen Folge des ZEIT-Podcasts "Alles gesagt" besprechen
Thea Dorn, Jochen Wegner, und Christian Amend das Buch /Trost. Briefe an Max./.
Sie nähern sich einem Kernproblem des modernen Menschen: wir seien darauf aus,
entweder vor einem unerwünschten Ereignis Risiken zu minimieren, oder nachher
Schadenersatz und Verantwortung zu fordern. Wir hätten verlernt, mit den
Unwägbarkeiten des Lebens umzugehen. Religiösität mit ihrer trostspendenen
Wirkung sei der entscheidende Ausweg.

Punkte, die ich ansprechen möchte:
- Thea Dorn zitiert NIetzsche platt als "Gott ist tot, der Mensch ist Gott, etc"
  → eingehen auf Nietzsche's "Gott ist tot" als Aufruf an Mensch in der
  "aufgeklärten" Welt, dass es eine neue Begründung für basale Dinge wie
  Menschenrechte, oder auch Trost, braucht. Glauben als mentaler Trick. "Gott
  ist tot" als Aufruf und mit Hoffnung besetzt, eine nachhaltigere, tiefere
  Basis zu finden.
- Sie geht zurück zur Religiösität. Ich als ostdeutsch sozialisiert kann nicht
  zurückgehen.
  Ich wurde als Kind nicht an Glauben herangeführt, es bleibt für mich ein
  unzugängliches Thema, welches nicht als ehrlich und wahren Trost annehmen
  kann. Ich weiß unverrückbar, dass das Leben ein kurzer, zufälliger Moment ist,
  dass nach dem Tod nichts ist, dass das Leben am Ende keinen höheren Sinn hat.
  Dies ist mein Ausgangspunkt. Ist dies der Grund, warum ich bei diesen
  Überlegungen keine Hoffnungslosigkeit spüre? Ich muss nicht dabei verweilen,
  ich kann einen Schritt weitergehen: letztendlich zählt das, was ich in meinem
  jetzigen Leben tue.
- Dass es Leben gibt, ist chemischer Zufall, dass es menschliches Leben gibt,
  ist evolutionärer Zufall, dass ich in einem reichen Land geboren werde, ist
  geschichtlicher Zufall, dass meine Eltern mich gut versorgen und großziehen
  können, ist familiärer Zufall. Brauchen wir eine Zufallsethik? Wenn so viele
  Teile unserer Existenz Zufall sind, ist das genug, um Trost zu spenden?
- Trifft das Unheil ein, ist dies ein Schicksalsschlag, aber nicht auch eine
  statistische Größe? Das Medizinstudium zeigt mir: die ganze Zeit erkranken
  Menschen, während ich oft glimpflich davonkomme. Ich bin nicht mit 18J in
  einen tödlichen Verkehrsunfall verwickelt worden. Ich bin nicht mit 23J an
  akuter Leukämie gestorben. Sehe ich diese statistischen Bedrohungen die ganze
  Zeit als reale Bedrohungen, werde ich gewiss verrückt, verzweifeln,
  hoffnungslos.
- Ich bin es jedoch nicht. Warum nicht? Gewiss aufgrund einer gewissen stoischen
  Haltung. Das reicht aber nicht, es braucht auch einen aktiven Part -
  Risikominimierung bietet letztlich dieses Gewissen: "ich habe mein möglichstes
  getan". Christian Drosten hatte eine ähnliche Losung: wir müssen besorgt sein
  und Maßnahmen treffen - aber nicht panisch.

Weiteres Thema: Thea Dorn sagt, Naturwissenschaftler*innen wägen gegeneinander
ab: wir rechnen aus, was wieviel Leid bringt, dann nehmen wir das, was weniger
bringt. Das sei Utilitarismus.  Sie jedoch sagt: wir müssen abwägen von Leben
retten vs "Freiheit".

- mit Friederike Schmitz: Abwägen im juristischen Sinne IST Utilitarismus!
** TODO Reading "The Shadow of the Sun" by Ryszard Kapuściński       :@books:
:PROPERTIES:
:EXPORT_FILE_NAME: shadow-of-sun
:END:
- State "TODO"       from "PENDING"    [2021-01-13 Mi 23:24]
- State "PENDING"    from "DONE"       [2021-01-13 Mi 23:24]
General impression: thoughtful book, mostly he tries to avoid [[https://www.youtube.com/watch?v=D9Ihs241zeg][single stories]] and
gives an impression of different scenes in or between different African
countries from the end of the 1950s till the 1990s. From time to time he tries
to explain certain view or mentalities in African countries, which might come of
as condescending from todays view and be of more interest to non-African readers
than to African readers.

#+hugo: more

In this blog post I will share the more impressionist quotes I liked, while some
historical takeaways will be collected in [[#africa][Notes]]
**** p 29: Course and temperature of the /first greeting/ defines fate of the relationship
- from very first second: exhibit enormous primal joy and geniality
- extend hand in large, vigorous gesture
- loud /laughter/, many questions
**** p 36ff.: colonial heritage
- a state wherein the civil servant received renumeration beyond all measure
  and reason (white low burocratic suddenly gets villa, servants, ...)
  + after independence this system gives fast rise to new elites
  + french: /la politique du ventre/ (... of the stomach)
- 10.000 kingodms, federations and stateless, but independent tribal
  associations crammed in ~40 colonies! (without asking)
- ports - only leeches on the body of Africa, points of export for slaves,
  gold and ivory
- p52: *Why Indians built the railway*
  + White worker from Europe \to was master, could not do physical labour
  + African worker \to "did not exist", the concept of wages was missing and
    British had system of forced labour later
- p82: *Islands around Africa*
  + Were bases for sailors, merchants, and robbers (especially Europeans)
  + For unstable African boats hard to reach \to spot for concentration camps
    for slave trade
- p83: The philosophy that inspired the construction of [[https://en.wikipedia.org/wiki/Kolyma_Tales][Kolyma]] and [[https://en.wikipedia.org/wiki/Auschwitz_concentration_camp][Auschwitz]],
  one of obsessive content and hatred, vileness and brutality, was formulated
  and set down centuries earlier by the captains of the /Martha/ and the /Progress/,
  the [[https://en.wikipedia.org/wiki/Mary_Ann_(1772_ship)][Marie Ann]] and the /Rainbow/
**** p60: Secrets of Serengeti
- lions attacking humans \to are old outcasts
- where are the elephant cemetries \to on bottom of lakes
**** Europeans, Africans and Racism
- p70: Poland vs Tansania
  + children asking Ryszard in Poland "And did you see many cannibals?"
  + Mothers in Tanganyika to their children: "You had better be good, or else
    the /mzungu/ (Swahili: the white man, the European) will eat you!"
- p110: So often I had felt irritated with people who arrived here, lived in
  "little Europe" or "little America" (e.g. in luxury hotels), and departed,
  bragging later that they had been to Africa, a place that in reality they had
  never seen.
**** wonders
- Lalibela: 11 great churches carved in stone and misery
